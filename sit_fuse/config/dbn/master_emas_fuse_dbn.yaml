
data:
 num_loader_workers: 10
 scale_data: True
 pixel_padding: 0
 number_channels: 84
 fill_value: -9999.0
 valid_min:  -900.0
 valid_max: 100000000
 subset_count: 1
 output_subset_count: 10
 reader_type: "numpy"
 reader_kwargs:
  no_arg: "no_arg"
 chan_dim: 0
 #delete_chans: [15,16,17,18,19,20,21,22,23,24,63,64,65,71,72,73,74,75,76,77,84,85,86,87]
 delete_chans: [75,84,85,86]
 transform_default:
  chans: []
  transform: []

 files_train: ["/data/nlahaye/remoteSensing/MASTER/MASTER_EMAS_Fuse2.npy"]

 files_test: ["/data/nlahaye/remoteSensing/MASTER/MASTER_EMAS_Fuse1.npy"]

scaler:
 name: "standard" 

output:
 out_dir: "/data/nlahaye/output/Learnergy/DBN_MASTER_EMAS_FUSE_MULTI_LAYER/"
 training_output: "output.data"
 training_mse: "rec_mse.data"
 testing_output: "output_test.data"
 testing_mse: "rec_mse_test.data"
 generate_train_output: False
 generate_output: False
 model: "dbn"

dbn:
 conv: False
 subset_training: 2000000
 deep_cluster: 800
 heir_tiers: 1
 overwrite_model: False
 tune_clust: False
 tune_dbn: False
 tune_scaler: False
 params:
  model_type: ["gaussian_selu","gaussian_selu"]
  dbn_arch: [2000,1000] #[250, 500, 2000] #, 2000]
  gibbs_steps: [1,1] #, 7, 7] #, 10] #, 25]
  learning_rate: [0.00001,0.00001] #, 0.0001, 0.0001] #, 0.01] #, 0.01]
  momentum: [0.95,0.95] #, 0.95, 0.95] #, 0.95] #, 0.95]
  decay: [0.0001,0.0001] #, 0.0001, 0.0001] #, 0.0001] #, 0.0001]
  temp: [1.0,1.0] #, 1.0, 1.0] ##[0.9, 0.75, 0.5] #, 1.0] #, 0.5] #, 0.5] 
  nesterov_accel: [True,True]
  normalize_learnergy: [False,True]
  batch_normalize: [False,False]

 training:
  use_gpu_preprocessing: False
  use_gpu: True
  world_size: 1
  rank: 0
  device_ids: ["2"]
  batch_size: 1000
  epochs: [10,10]
  cluster_batch_size: 1000
  cluster_epochs: 30
  cluster_gauss_noise_stdev: [0.01]
  cluster_lambda: 1.0

  heir_cluster_min_samples: 1000
  heir_cluster_gauss_noise_stdev: [0.01] #[0.001, 0.0001, 0.00001, 0.000001, 0.0]
  heir_epochs: 30
  heir_tune_subtrees: False
  heir_tune_subtree_list: []
  heir_deep_cluster: 100




