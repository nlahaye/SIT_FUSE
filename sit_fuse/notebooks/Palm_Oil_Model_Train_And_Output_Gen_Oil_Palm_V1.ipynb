{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **Environment setup.**"
      ],
      "metadata": {
        "id": "y22xv4q_9gqW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mXFHfn0fm4-A",
        "outputId": "e36471ac-929b-49d5-bb61-372612a99891"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.65.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.15.2+cu118)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.0.2+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.22.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.27.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Collecting GPUtil\n",
            "  Downloading GPUtil-1.4.0.tar.gz (5.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting netCDF4\n",
            "  Downloading netCDF4-1.6.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: geopandas in /usr/local/lib/python3.10/dist-packages (0.13.2)\n",
            "Collecting geocube\n",
            "  Downloading geocube-0.4.2-py3-none-any.whl (21 kB)\n",
            "Collecting dask_ml\n",
            "  Downloading dask_ml-2023.3.24-py3-none-any.whl (148 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m148.7/148.7 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting zarr\n",
            "  Downloading zarr-2.16.0-py3-none-any.whl (206 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m206.5/206.5 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cftime (from netCDF4)\n",
            "  Downloading cftime-1.6.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m42.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from netCDF4) (2023.7.22)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from netCDF4) (1.22.4)\n",
            "Requirement already satisfied: fiona>=1.8.19 in /usr/local/lib/python3.10/dist-packages (from geopandas) (1.9.4.post1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from geopandas) (23.1)\n",
            "Requirement already satisfied: pandas>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from geopandas) (1.5.3)\n",
            "Requirement already satisfied: pyproj>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from geopandas) (3.6.0)\n",
            "Requirement already satisfied: shapely>=1.7.1 in /usr/local/lib/python3.10/dist-packages (from geopandas) (2.0.1)\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.10/dist-packages (from geocube) (1.4.4)\n",
            "Requirement already satisfied: click>=6.0 in /usr/local/lib/python3.10/dist-packages (from geocube) (8.1.6)\n",
            "Collecting odc-geo (from geocube)\n",
            "  Downloading odc_geo-0.4.1-py3-none-any.whl (122 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.4/122.4 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rasterio (from geocube)\n",
            "  Downloading rasterio-1.3.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m76.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rioxarray>=0.4 (from geocube)\n",
            "  Downloading rioxarray-0.14.1-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.5/53.5 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from geocube) (1.10.1)\n",
            "Requirement already satisfied: xarray>=0.17 in /usr/local/lib/python3.10/dist-packages (from geocube) (2022.12.0)\n",
            "Requirement already satisfied: dask[array,dataframe]>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from dask_ml) (2022.12.1)\n",
            "Requirement already satisfied: distributed>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from dask_ml) (2022.12.1)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from dask_ml) (0.56.4)\n",
            "Requirement already satisfied: scikit-learn>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from dask_ml) (1.2.2)\n",
            "Collecting dask-glm>=0.2.0 (from dask_ml)\n",
            "  Downloading dask_glm-0.2.0-py2.py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: multipledispatch>=0.4.9 in /usr/local/lib/python3.10/dist-packages (from dask_ml) (1.0.0)\n",
            "Collecting asciitree (from zarr)\n",
            "  Downloading asciitree-0.3.3.tar.gz (4.0 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting fasteners (from zarr)\n",
            "  Downloading fasteners-0.18-py3-none-any.whl (18 kB)\n",
            "Collecting numcodecs>=0.10.0 (from zarr)\n",
            "  Downloading numcodecs-0.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m92.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cloudpickle>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from dask-glm>=0.2.0->dask_ml) (2.2.1)\n",
            "Requirement already satisfied: fsspec>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from dask[array,dataframe]>=2.4.0->dask_ml) (2023.6.0)\n",
            "Requirement already satisfied: partd>=0.3.10 in /usr/local/lib/python3.10/dist-packages (from dask[array,dataframe]>=2.4.0->dask_ml) (1.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from dask[array,dataframe]>=2.4.0->dask_ml) (6.0.1)\n",
            "Requirement already satisfied: toolz>=0.8.2 in /usr/local/lib/python3.10/dist-packages (from dask[array,dataframe]>=2.4.0->dask_ml) (0.12.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from distributed>=2.4.0->dask_ml) (3.1.2)\n",
            "Requirement already satisfied: locket>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from distributed>=2.4.0->dask_ml) (1.0.0)\n",
            "Requirement already satisfied: msgpack>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from distributed>=2.4.0->dask_ml) (1.0.5)\n",
            "Requirement already satisfied: psutil>=5.0 in /usr/local/lib/python3.10/dist-packages (from distributed>=2.4.0->dask_ml) (5.9.5)\n",
            "Requirement already satisfied: sortedcontainers!=2.0.0,!=2.0.1 in /usr/local/lib/python3.10/dist-packages (from distributed>=2.4.0->dask_ml) (2.4.0)\n",
            "Requirement already satisfied: tblib>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from distributed>=2.4.0->dask_ml) (2.0.0)\n",
            "Requirement already satisfied: tornado>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from distributed>=2.4.0->dask_ml) (6.3.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from distributed>=2.4.0->dask_ml) (1.26.16)\n",
            "Requirement already satisfied: zict>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from distributed>=2.4.0->dask_ml) (3.0.0)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.10/dist-packages (from fiona>=1.8.19->geopandas) (23.1.0)\n",
            "Requirement already satisfied: click-plugins>=1.0 in /usr/local/lib/python3.10/dist-packages (from fiona>=1.8.19->geopandas) (1.1.1)\n",
            "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.10/dist-packages (from fiona>=1.8.19->geopandas) (0.7.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from fiona>=1.8.19->geopandas) (1.16.0)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->dask_ml) (0.39.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->dask_ml) (67.7.2)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from numcodecs>=0.10.0->zarr) (0.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.0->geopandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.0->geopandas) (2022.7.1)\n",
            "Collecting affine (from rasterio->geocube)\n",
            "  Downloading affine-2.4.0-py3-none-any.whl (15 kB)\n",
            "Collecting snuggs>=1.4.1 (from rasterio->geocube)\n",
            "  Downloading snuggs-1.4.7-py3-none-any.whl (5.4 kB)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.2.0->dask_ml) (1.3.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.2.0->dask_ml) (3.2.0)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.10/dist-packages (from odc-geo->geocube) (5.3.1)\n",
            "Requirement already satisfied: pyparsing>=2.1.6 in /usr/local/lib/python3.10/dist-packages (from snuggs>=1.4.1->rasterio->geocube) (3.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->distributed>=2.4.0->dask_ml) (2.1.3)\n",
            "Building wheels for collected packages: GPUtil, asciitree\n",
            "  Building wheel for GPUtil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for GPUtil: filename=GPUtil-1.4.0-py3-none-any.whl size=7393 sha256=673896833653b601251700bce25cbfed039c7d30387ee57a2a6ac633be5b6fc0\n",
            "  Stored in directory: /root/.cache/pip/wheels/a9/8a/bd/81082387151853ab8b6b3ef33426e98f5cbfebc3c397a9d4d0\n",
            "  Building wheel for asciitree (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for asciitree: filename=asciitree-0.3.3-py3-none-any.whl size=5033 sha256=2c7238ff81aa2f5660d3b3f5b7c5888016311c78e2bc498ab2fc5192febf5965\n",
            "  Stored in directory: /root/.cache/pip/wheels/7f/4e/be/1171b40f43b918087657ec57cf3b81fa1a2e027d8755baa184\n",
            "Successfully built GPUtil asciitree\n",
            "Installing collected packages: GPUtil, asciitree, snuggs, numcodecs, fasteners, cftime, affine, zarr, rasterio, odc-geo, netCDF4, rioxarray, dask-glm, geocube, dask_ml\n",
            "Successfully installed GPUtil-1.4.0 affine-2.4.0 asciitree-0.3.3 cftime-1.6.2 dask-glm-0.2.0 dask_ml-2023.3.24 fasteners-0.18 geocube-0.4.2 netCDF4-1.6.4 numcodecs-0.11.0 odc-geo-0.4.1 rasterio-1.3.8 rioxarray-0.14.1 snuggs-1.4.7 zarr-2.16.0\n",
            "Looking in indexes: https://pypi.org/simple, https://pypi.nvidia.com\n",
            "Collecting cuml-cu11\n",
            "  Downloading https://pypi.nvidia.com/cuml-cu11/cuml_cu11-23.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1079.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 GB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cudf-cu11==23.6.* (from cuml-cu11)\n",
            "  Downloading https://pypi.nvidia.com/cudf-cu11/cudf_cu11-23.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (489.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m489.3/489.3 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cupy-cuda11x>=12.0.0 (from cuml-cu11)\n",
            "  Downloading cupy_cuda11x-12.1.0-cp310-cp310-manylinux2014_x86_64.whl (89.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.3/89.3 MB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dask-cuda==23.6.* (from cuml-cu11)\n",
            "  Downloading dask_cuda-23.6.0-py3-none-any.whl (125 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.2/125.2 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dask-cudf-cu11==23.6.* (from cuml-cu11)\n",
            "  Downloading https://pypi.nvidia.com/dask-cudf-cu11/dask_cudf_cu11-23.6.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.6/79.6 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dask==2023.3.2 (from cuml-cu11)\n",
            "  Downloading dask-2023.3.2-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m65.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting distributed==2023.3.2.1 (from cuml-cu11)\n",
            "  Downloading distributed-2023.3.2.1-py3-none-any.whl (957 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m957.1/957.1 kB\u001b[0m \u001b[31m66.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.10/dist-packages (from cuml-cu11) (1.3.1)\n",
            "Collecting numba>=0.57 (from cuml-cu11)\n",
            "  Downloading numba-0.57.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m98.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting raft-dask-cu11==23.6.* (from cuml-cu11)\n",
            "  Downloading https://pypi.nvidia.com/raft-dask-cu11/raft_dask_cu11-23.6.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (214.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m214.7/214.7 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from cuml-cu11) (1.10.1)\n",
            "Collecting treelite==3.2.0 (from cuml-cu11)\n",
            "  Downloading treelite-3.2.0-py3-none-manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m74.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting treelite-runtime==3.2.0 (from cuml-cu11)\n",
            "  Downloading treelite_runtime-3.2.0-py3-none-manylinux2014_x86_64.whl (198 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m198.2/198.2 kB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cachetools in /usr/local/lib/python3.10/dist-packages (from cudf-cu11==23.6.*->cuml-cu11) (5.3.1)\n",
            "Collecting cubinlinker-cu11 (from cudf-cu11==23.6.*->cuml-cu11)\n",
            "  Downloading https://pypi.nvidia.com/cubinlinker-cu11/cubinlinker_cu11-0.3.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m109.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cuda-python<12.0,>=11.7.1 (from cudf-cu11==23.6.*->cuml-cu11)\n",
            "  Downloading cuda_python-11.8.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.5/16.5 MB\u001b[0m \u001b[31m93.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from cudf-cu11==23.6.*->cuml-cu11) (2023.6.0)\n",
            "Requirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.10/dist-packages (from cudf-cu11==23.6.*->cuml-cu11) (1.22.4)\n",
            "Collecting nvtx>=0.2.1 (from cudf-cu11==23.6.*->cuml-cu11)\n",
            "  Downloading nvtx-0.2.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (553 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m553.1/553.1 kB\u001b[0m \u001b[31m48.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from cudf-cu11==23.6.*->cuml-cu11) (23.1)\n",
            "Requirement already satisfied: pandas<1.6.0dev0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from cudf-cu11==23.6.*->cuml-cu11) (1.5.3)\n",
            "Collecting protobuf<4.22,>=4.21.6 (from cudf-cu11==23.6.*->cuml-cu11)\n",
            "  Downloading protobuf-4.21.12-cp37-abi3-manylinux2014_x86_64.whl (409 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m409.8/409.8 kB\u001b[0m \u001b[31m38.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ptxcompiler-cu11 (from cudf-cu11==23.6.*->cuml-cu11)\n",
            "  Downloading https://pypi.nvidia.com/ptxcompiler-cu11/ptxcompiler_cu11-0.7.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m114.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyarrow==11.* (from cudf-cu11==23.6.*->cuml-cu11)\n",
            "  Downloading pyarrow-11.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.9/34.9 MB\u001b[0m \u001b[31m48.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rmm-cu11==23.6.* (from cudf-cu11==23.6.*->cuml-cu11)\n",
            "  Downloading https://pypi.nvidia.com/rmm-cu11/rmm_cu11-23.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m82.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from cudf-cu11==23.6.*->cuml-cu11) (4.7.1)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from dask==2023.3.2->cuml-cu11) (8.1.6)\n",
            "Requirement already satisfied: cloudpickle>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from dask==2023.3.2->cuml-cu11) (2.2.1)\n",
            "Requirement already satisfied: partd>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from dask==2023.3.2->cuml-cu11) (1.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from dask==2023.3.2->cuml-cu11) (6.0.1)\n",
            "Requirement already satisfied: toolz>=0.8.2 in /usr/local/lib/python3.10/dist-packages (from dask==2023.3.2->cuml-cu11) (0.12.0)\n",
            "Collecting importlib-metadata>=4.13.0 (from dask==2023.3.2->cuml-cu11)\n",
            "  Downloading importlib_metadata-6.8.0-py3-none-any.whl (22 kB)\n",
            "Collecting pynvml<11.5,>=11.0.0 (from dask-cuda==23.6.*->cuml-cu11)\n",
            "  Downloading pynvml-11.4.1-py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.0/47.0 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: zict>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from dask-cuda==23.6.*->cuml-cu11) (3.0.0)\n",
            "Requirement already satisfied: jinja2>=2.10.3 in /usr/local/lib/python3.10/dist-packages (from distributed==2023.3.2.1->cuml-cu11) (3.1.2)\n",
            "Requirement already satisfied: locket>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from distributed==2023.3.2.1->cuml-cu11) (1.0.0)\n",
            "Requirement already satisfied: msgpack>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from distributed==2023.3.2.1->cuml-cu11) (1.0.5)\n",
            "Requirement already satisfied: psutil>=5.7.0 in /usr/local/lib/python3.10/dist-packages (from distributed==2023.3.2.1->cuml-cu11) (5.9.5)\n",
            "Requirement already satisfied: sortedcontainers>=2.0.5 in /usr/local/lib/python3.10/dist-packages (from distributed==2023.3.2.1->cuml-cu11) (2.4.0)\n",
            "Requirement already satisfied: tblib>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from distributed==2023.3.2.1->cuml-cu11) (2.0.0)\n",
            "Requirement already satisfied: tornado>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from distributed==2023.3.2.1->cuml-cu11) (6.3.1)\n",
            "Requirement already satisfied: urllib3>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from distributed==2023.3.2.1->cuml-cu11) (1.26.16)\n",
            "Collecting pylibraft-cu11==23.6.* (from raft-dask-cu11==23.6.*->cuml-cu11)\n",
            "  Downloading https://pypi.nvidia.com/pylibraft-cu11/pylibraft_cu11-23.6.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (471.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m471.7/471.7 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ucx-py-cu11==0.32.* (from raft-dask-cu11==23.6.*->cuml-cu11)\n",
            "  Downloading https://pypi.nvidia.com/ucx-py-cu11/ucx_py_cu11-0.32.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m103.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fastrlock>=0.5 in /usr/local/lib/python3.10/dist-packages (from cupy-cuda11x>=12.0.0->cuml-cu11) (0.8.1)\n",
            "Collecting llvmlite<0.41,>=0.40.0dev0 (from numba>=0.57->cuml-cu11)\n",
            "  Downloading llvmlite-0.40.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (42.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.1/42.1 MB\u001b[0m \u001b[31m44.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cython in /usr/local/lib/python3.10/dist-packages (from cuda-python<12.0,>=11.7.1->cudf-cu11==23.6.*->cuml-cu11) (0.29.36)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=4.13.0->dask==2023.3.2->cuml-cu11) (3.16.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=2.10.3->distributed==2023.3.2.1->cuml-cu11) (2.1.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas<1.6.0dev0,>=1.3->cudf-cu11==23.6.*->cuml-cu11) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<1.6.0dev0,>=1.3->cudf-cu11==23.6.*->cuml-cu11) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas<1.6.0dev0,>=1.3->cudf-cu11==23.6.*->cuml-cu11) (1.16.0)\n",
            "Installing collected packages: ptxcompiler-cu11, nvtx, cubinlinker-cu11, pynvml, pyarrow, protobuf, llvmlite, importlib-metadata, cupy-cuda11x, cuda-python, ucx-py-cu11, treelite-runtime, treelite, numba, dask, rmm-cu11, distributed, pylibraft-cu11, dask-cuda, cudf-cu11, raft-dask-cu11, dask-cudf-cu11, cuml-cu11\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 9.0.0\n",
            "    Uninstalling pyarrow-9.0.0:\n",
            "      Successfully uninstalled pyarrow-9.0.0\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "  Attempting uninstall: llvmlite\n",
            "    Found existing installation: llvmlite 0.39.1\n",
            "    Uninstalling llvmlite-0.39.1:\n",
            "      Successfully uninstalled llvmlite-0.39.1\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib-metadata 4.6.4\n",
            "    Uninstalling importlib-metadata-4.6.4:\n",
            "      Successfully uninstalled importlib-metadata-4.6.4\n",
            "  Attempting uninstall: cupy-cuda11x\n",
            "    Found existing installation: cupy-cuda11x 11.0.0\n",
            "    Uninstalling cupy-cuda11x-11.0.0:\n",
            "      Successfully uninstalled cupy-cuda11x-11.0.0\n",
            "  Attempting uninstall: numba\n",
            "    Found existing installation: numba 0.56.4\n",
            "    Uninstalling numba-0.56.4:\n",
            "      Successfully uninstalled numba-0.56.4\n",
            "  Attempting uninstall: dask\n",
            "    Found existing installation: dask 2022.12.1\n",
            "    Uninstalling dask-2022.12.1:\n",
            "      Successfully uninstalled dask-2022.12.1\n",
            "  Attempting uninstall: distributed\n",
            "    Found existing installation: distributed 2022.12.1\n",
            "    Uninstalling distributed-2022.12.1:\n",
            "      Successfully uninstalled distributed-2022.12.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pandas-gbq 0.17.9 requires pyarrow<10.0dev,>=3.0.0, but you have pyarrow 11.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed cubinlinker-cu11-0.3.0.post1 cuda-python-11.8.2 cudf-cu11-23.6.1 cuml-cu11-23.6.0 cupy-cuda11x-12.1.0 dask-2023.3.2 dask-cuda-23.6.0 dask-cudf-cu11-23.6.0 distributed-2023.3.2.1 importlib-metadata-6.8.0 llvmlite-0.40.1 numba-0.57.1 nvtx-0.2.6 protobuf-4.21.12 ptxcompiler-cu11-0.7.0.post1 pyarrow-11.0.0 pylibraft-cu11-23.6.2 pynvml-11.4.1 raft-dask-cu11-23.6.2 rmm-cu11-23.6.0 treelite-3.2.0 treelite-runtime-3.2.0 ucx-py-cu11-0.32.0\n"
          ]
        }
      ],
      "source": [
        "!pip3 install tqdm torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "!pip3 install GPUtil netCDF4 geopandas geocube dask_ml zarr\n",
        "!pip3 install cuml-cu11 --extra-index-url=https://pypi.nvidia.com"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Pull code from GitHub.**"
      ],
      "metadata": {
        "id": "1efsJNFl9nCa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVYe0ETJn8mW",
        "outputId": "83247286-b8d1-4a37-c529-9726ecbac62f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'learnergy'...\n",
            "remote: Enumerating objects: 3549, done.\u001b[K\n",
            "remote: Counting objects: 100% (966/966), done.\u001b[K\n",
            "remote: Compressing objects: 100% (374/374), done.\u001b[K\n",
            "remote: Total 3549 (delta 626), reused 888 (delta 585), pack-reused 2583\u001b[K\n",
            "Receiving objects: 100% (3549/3549), 811.03 KiB | 5.83 MiB/s, done.\n",
            "Resolving deltas: 100% (2275/2275), done.\n",
            "Cloning into 'SIT_FUSE'...\n",
            "remote: Enumerating objects: 1169, done.\u001b[K\n",
            "remote: Counting objects: 100% (101/101), done.\u001b[K\n",
            "remote: Compressing objects: 100% (64/64), done.\u001b[K\n",
            "remote: Total 1169 (delta 55), reused 73 (delta 37), pack-reused 1068\u001b[K\n",
            "Receiving objects: 100% (1169/1169), 399.40 KiB | 10.79 MiB/s, done.\n",
            "Resolving deltas: 100% (793/793), done.\n"
          ]
        }
      ],
      "source": [
        "!rm -Rf /content/learnergy/\n",
        "!rm -Rf /content/SIT_FUSE\n",
        "!git clone https://github.com/nlahaye/learnergy.git\n",
        "!git clone https://github.com/nlahaye/SIT_FUSE.git"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Mount GDrive - TODO change out for VRT access**"
      ],
      "metadata": {
        "id": "8byhqFwC99Aw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQ-URFt5o6gF",
        "outputId": "994a974b-9433-4591-e6f4-3324571a0f34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Run Initial Feature Extraction & Top Level Clustering**"
      ],
      "metadata": {
        "id": "6m84awvJ-EZK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pFhm2JOVnP2T",
        "outputId": "6b701047-fe0f-4f2c-a8d9-5fa0216bae3e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "env: PYTHONPATH=$PYTHONPATH:/content/learnergy/:/content/SIT_FUSE/\n",
            "HERE CUDA_VISIBLE_DEVICES 0\n",
            "/content/drive/MyDrive/oil_palm_data_science/ucayali_condensed_stacks_2020_h1v1.tiff\n",
            "(4, 5000, 5000)\n",
            "STATS -8.9276705 30.682579 -0.00019300147 1.0001402\n",
            "2023-07-27 07:44:57,256 - learnergy.models.deep.dbn — INFO — Overriding class: Model -> DBN.\n",
            "2023-07-27 07:45:05,986 - learnergy.core.model — DEBUG — Device: cuda.\n",
            "2023-07-27 07:45:05,986 - learnergy.models.gaussian.gaussian_rbm — INFO — Overriding class: GaussianRBM -> GaussianSeluRBM.\n",
            "2023-07-27 07:45:05,986 - learnergy.models.gaussian.gaussian_rbm — INFO — Overriding class: RBM -> GaussianRBM.\n",
            "2023-07-27 07:45:05,986 - learnergy.models.bernoulli.rbm — INFO — Overriding class: Model -> RBM.\n",
            "2023-07-27 07:45:05,987 - learnergy.core.model — DEBUG — Device: cuda.\n",
            "2023-07-27 07:45:07,152 - learnergy.models.bernoulli.rbm — INFO — Class overrided.\n",
            "2023-07-27 07:45:07,152 - learnergy.models.bernoulli.rbm — DEBUG — Size: (36, 2000) | Learning: CD-10 | Hyperparameters: lr = 0.0001, momentum = 0.0, decay = 0.0001, T = 1.0.\n",
            "2023-07-27 07:45:07,152 - learnergy.models.gaussian.gaussian_rbm — INFO — Class overrided.\n",
            "2023-07-27 07:45:07,152 - learnergy.models.gaussian.gaussian_rbm — INFO — Class overrided.\n",
            "2023-07-27 07:45:07,152 - learnergy.models.deep.dbn — INFO — Class overrided.\n",
            "2023-07-27 07:45:07,152 - learnergy.models.deep.dbn — DEBUG — Number of layers: 1.\n",
            "2023-07-27 07:45:07,197 - learnergy.core.model — DEBUG — Device: cuda.\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "100% 35685/35685 [04:44<00:00, 125.52it/s]\n",
            "Loading pre-existing model\n",
            "/content/drive/MyDrive/oil_palm_data_science/ucayali_condensed_stacks_2020_h1v1.tiff\n",
            "(4, 5000, 5000)\n",
            "STATS -8.9276705 30.682579 -0.00019300204 1.0001391\n",
            "100% 4997/4997 [12:20<00:00,  6.75it/s]\n",
            "SAVING /content/drive/MyDrive/oil_palm_data_science/ML_Test/ucayali_condensed_stacks_2020_h1v1.tiff.clustoutput_test.data\n",
            "2165.657175973\n"
          ]
        }
      ],
      "source": [
        "%env PYTHONPATH=$PYTHONPATH:/content/learnergy/:/content/SIT_FUSE/\n",
        "!cd SIT_FUSE; torchrun --nnodes=1 --nproc_per_node=1 dbn_learnergy.py --yaml /content/SIT_FUSE/config/dbn/palm_oil_dbn_colab.yaml"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Discretize Model Output - Assign Top Level Labels/Clusters**"
      ],
      "metadata": {
        "id": "eoueQC9u-kjv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1sh4yjdim6_u",
        "outputId": "611b1c31-ab90-4a62-9df4-936ab7224495"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "env: PYTHONPATH=$PYTHONPATH:/content/learnergy/:/content/SIT_FUSE/\n",
            "/content/drive/MyDrive/oil_palm_data_science/ML_Test/ucayali_condensed_stacks_2020_h1v1.tiff.clustoutput_test.data\n",
            "(150,) UNIQUE LABELS\n",
            "ASSIGNING LABELS 0 150\n",
            "(5000, 5000) (24985000,) (24985000, 3)\n",
            "FINISHED WITH LABEL ASSIGNMENT\n",
            "FINAL DATA TO DASK\n",
            "HERE CLUSTERS MIN MAX MEAN STD -1.0 149.0 100.34557424 35.56576003243361\n",
            "102.4042574619998\n"
          ]
        }
      ],
      "source": [
        "%env PYTHONPATH=$PYTHONPATH:/content/learnergy/:/content/SIT_FUSE/\n",
        "!cd SIT_FUSE; python3 discretize_clusters.py --yaml /content/SIT_FUSE/config/cluster/discretize_palm_oil_colab.yaml"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Visualize Initial Results**"
      ],
      "metadata": {
        "id": "ro15XP8b-t8Z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oFyEKG72onXy"
      },
      "outputs": [],
      "source": [
        "# import image module\n",
        "from IPython.display import Image\n",
        "\n",
        "# get the image\n",
        "Image(url=\"/content/drive/MyDrive/oil_palm_data_science/ML_Test/ucayali_condensed_stacks_2020_h1v1.tiff.clustoutput_test.data_150clusters.png\", width=300, height=300)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Create Heirarchical Tree/Dendrogram of Labels - Assign More Precise Labels**"
      ],
      "metadata": {
        "id": "vJR8V3_V_Ikn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0SUpTjUH4qpq",
        "outputId": "50bf6dd5-4262-4877-af0e-83863d1abc38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: PYTHONPATH=$PYTHONPATH:/content/learnergy/:/content/SIT_FUSE/\n",
            "/content/drive/MyDrive/oil_palm_data_science/ucayali_condensed_stacks_2020_h1v1.tiff\n",
            "(4, 5000, 5000)\n",
            "STATS -8.9276705 30.682579 -0.00019300207 1.0001425\n",
            "2023-07-27 08:23:53,562 - learnergy.models.deep.dbn — INFO — Overriding class: Model -> DBN.\n",
            "2023-07-27 08:24:01,344 - learnergy.core.model — DEBUG — Device: cuda.\n",
            "2023-07-27 08:24:01,344 - learnergy.models.gaussian.gaussian_rbm — INFO — Overriding class: GaussianRBM -> GaussianSeluRBM.\n",
            "2023-07-27 08:24:01,344 - learnergy.models.gaussian.gaussian_rbm — INFO — Overriding class: RBM -> GaussianRBM.\n",
            "2023-07-27 08:24:01,344 - learnergy.models.bernoulli.rbm — INFO — Overriding class: Model -> RBM.\n",
            "2023-07-27 08:24:01,345 - learnergy.core.model — DEBUG — Device: cuda.\n",
            "2023-07-27 08:24:04,870 - learnergy.models.bernoulli.rbm — INFO — Class overrided.\n",
            "2023-07-27 08:24:04,871 - learnergy.models.bernoulli.rbm — DEBUG — Size: (36, 2000) | Learning: CD-10 | Hyperparameters: lr = 0.0001, momentum = 0.0, decay = 0.0001, T = 1.0.\n",
            "2023-07-27 08:24:04,871 - learnergy.models.gaussian.gaussian_rbm — INFO — Class overrided.\n",
            "2023-07-27 08:24:04,871 - learnergy.models.gaussian.gaussian_rbm — INFO — Class overrided.\n",
            "2023-07-27 08:24:04,871 - learnergy.models.deep.dbn — INFO — Class overrided.\n",
            "2023-07-27 08:24:04,871 - learnergy.models.deep.dbn — DEBUG — Number of layers: 1.\n",
            "2023-07-27 08:24:13,343 - learnergy.core.model — DEBUG — Device: cuda.\n",
            "Loading pre-existing model\n",
            "2023-07-27 08:24:13,379 - learnergy.core.model — DEBUG — Device: cuda.\n",
            "100% 249801/249801 [1:38:14<00:00, 42.38it/s]\n",
            "LABEL INIT tensor(3) torch.Size([243942])\n",
            "LABEL INIT tensor(4) torch.Size([81476])\n",
            "LABEL INIT tensor(16) torch.Size([325399])\n",
            "LABEL INIT tensor(34) torch.Size([360288])\n",
            "LABEL INIT tensor(41) torch.Size([389331])\n",
            "LABEL INIT tensor(56) torch.Size([8471])\n",
            "LABEL INIT tensor(58) torch.Size([354826])\n",
            "LABEL INIT tensor(64) torch.Size([116221])\n",
            "LABEL INIT tensor(65) torch.Size([12290])\n",
            "LABEL INIT tensor(74) torch.Size([56664])\n",
            "LABEL INIT tensor(75) torch.Size([28113])\n",
            "LABEL INIT tensor(78) torch.Size([97056])\n",
            "LABEL INIT tensor(80) torch.Size([386147])\n",
            "LABEL INIT tensor(88) torch.Size([819417])\n",
            "LABEL INIT tensor(89) torch.Size([7079307])\n",
            "LABEL INIT tensor(105) torch.Size([164470])\n",
            "LABEL INIT tensor(112) torch.Size([1851729])\n",
            "LABEL INIT tensor(114) torch.Size([953903])\n",
            "LABEL INIT tensor(115) torch.Size([969135])\n",
            "LABEL INIT tensor(121) torch.Size([15730])\n",
            "LABEL INIT tensor(122) torch.Size([434664])\n",
            "LABEL INIT tensor(124) torch.Size([329792])\n",
            "LABEL INIT tensor(135) torch.Size([279452])\n",
            "LABEL INIT tensor(137) torch.Size([29378])\n",
            "LABEL INIT tensor(138) torch.Size([2206440])\n",
            "LABEL INIT tensor(140) torch.Size([275984])\n",
            "LABEL INIT tensor(141) torch.Size([54708])\n",
            "LABEL INIT tensor(144) torch.Size([2293300])\n",
            "LABEL INIT tensor(146) torch.Size([20525])\n",
            "LABEL INIT tensor(149) torch.Size([1024867])\n",
            "LABEL INIT tensor(14) torch.Size([5048])\n",
            "LABEL INIT tensor(15) torch.Size([102690])\n",
            "LABEL INIT tensor(17) torch.Size([167650])\n",
            "LABEL INIT tensor(26) torch.Size([98058])\n",
            "LABEL INIT tensor(42) torch.Size([335626])\n",
            "LABEL INIT tensor(85) torch.Size([375165])\n",
            "LABEL INIT tensor(98) torch.Size([76877])\n",
            "LABEL INIT tensor(99) torch.Size([209195])\n",
            "LABEL INIT tensor(113) torch.Size([176979])\n",
            "LABEL INIT tensor(123) torch.Size([108842])\n",
            "LABEL INIT tensor(147) torch.Size([94944])\n",
            "LABEL INIT tensor(29) torch.Size([156779])\n",
            "LABEL INIT tensor(37) torch.Size([190356])\n",
            "LABEL INIT tensor(77) torch.Size([4557])\n",
            "LABEL INIT tensor(81) torch.Size([52102])\n",
            "LABEL INIT tensor(91) torch.Size([39241])\n",
            "LABEL INIT tensor(96) torch.Size([55433])\n",
            "LABEL INIT tensor(125) torch.Size([123980])\n",
            "LABEL INIT tensor(25) torch.Size([106607])\n",
            "LABEL INIT tensor(86) torch.Size([48279])\n",
            "LABEL INIT tensor(118) torch.Size([36770])\n",
            "LABEL INIT tensor(133) torch.Size([40770])\n",
            "LABEL INIT tensor(148) torch.Size([76411])\n",
            "LABEL INIT tensor(7) torch.Size([75428])\n",
            "LABEL INIT tensor(87) torch.Size([11104])\n",
            "LABEL INIT tensor(107) torch.Size([45068])\n",
            "LABEL INIT tensor(108) torch.Size([47969])\n",
            "LABEL INIT tensor(126) torch.Size([31624])\n",
            "LABEL INIT tensor(2) torch.Size([5933])\n",
            "LABEL INIT tensor(90) torch.Size([19977])\n",
            "LABEL INIT tensor(93) torch.Size([27297])\n",
            "LABEL INIT tensor(97) torch.Size([73471])\n",
            "LABEL INIT tensor(33) torch.Size([2258])\n",
            "LABEL INIT tensor(67) torch.Size([6660])\n",
            "LABEL INIT tensor(131) torch.Size([34524])\n",
            "LABEL INIT tensor(18) torch.Size([5500])\n",
            "LABEL INIT tensor(106) torch.Size([4490])\n",
            "LABEL INIT tensor(102) torch.Size([72060])\n",
            "LABEL INIT tensor(101) torch.Size([4286])\n",
            "LABEL INIT tensor(132) torch.Size([4148])\n",
            "LABEL INIT tensor(23) torch.Size([10438])\n",
            "LABEL INIT tensor(116) torch.Size([3455])\n",
            "LABEL INIT tensor(134) torch.Size([11510])\n",
            "LABEL INIT tensor(145) torch.Size([71604])\n",
            "LABEL INIT tensor(62) torch.Size([28013])\n",
            "LABEL INIT tensor(66) torch.Size([26214])\n",
            "LABEL INIT tensor(120) torch.Size([25084])\n",
            "LABEL INIT tensor(94) torch.Size([17482])\n",
            "LABEL INIT tensor(104) torch.Size([28983])\n",
            "LABEL INIT tensor(139) torch.Size([18015])\n",
            "LABEL INIT tensor(1) torch.Size([5958])\n",
            "LABEL INIT tensor(48) torch.Size([11755])\n",
            "LABEL INIT tensor(63) torch.Size([2902])\n",
            "LABEL INIT tensor(128) torch.Size([1201])\n",
            "LABEL INIT tensor(30) torch.Size([40981])\n",
            "LABEL INIT tensor(32) torch.Size([19795])\n",
            "LABEL INIT tensor(10) torch.Size([6036])\n",
            "LABEL INIT tensor(84) torch.Size([1419])\n",
            "LABEL INIT tensor(45) torch.Size([2941])\n",
            "LABEL INIT tensor(55) torch.Size([7658])\n",
            "LABEL INIT tensor(0) torch.Size([22682])\n",
            "LABEL INIT tensor(76) torch.Size([115])\n",
            "LABEL INIT tensor(27) torch.Size([25509])\n",
            "LABEL INIT tensor(72) torch.Size([4700])\n",
            "LABEL INIT tensor(35) torch.Size([700])\n",
            "LABEL INIT tensor(52) torch.Size([8671])\n",
            "LABEL INIT tensor(100) torch.Size([409])\n",
            "LABEL INIT tensor(119) torch.Size([14577])\n",
            "LABEL INIT tensor(54) torch.Size([21120])\n",
            "LABEL INIT tensor(109) torch.Size([793])\n",
            "LABEL INIT tensor(51) torch.Size([1536])\n",
            "LABEL INIT tensor(43) torch.Size([6932])\n",
            "LABEL INIT tensor(9) torch.Size([5074])\n",
            "LABEL INIT tensor(24) torch.Size([17303])\n",
            "LABEL INIT tensor(44) torch.Size([5305])\n",
            "LABEL INIT tensor(13) torch.Size([6731])\n",
            "LABEL INIT tensor(130) torch.Size([8201])\n",
            "LABEL INIT tensor(50) torch.Size([4841])\n",
            "LABEL INIT tensor(92) torch.Size([7938])\n",
            "LABEL INIT tensor(59) torch.Size([911])\n",
            "LABEL INIT tensor(117) torch.Size([431])\n",
            "LABEL INIT tensor(82) torch.Size([6701])\n",
            "LABEL INIT tensor(5) torch.Size([7077])\n",
            "LABEL INIT tensor(79) torch.Size([3213])\n",
            "LABEL INIT tensor(28) torch.Size([7199])\n",
            "LABEL INIT tensor(36) torch.Size([241])\n",
            "LABEL INIT tensor(57) torch.Size([352])\n",
            "LABEL INIT tensor(70) torch.Size([3472])\n",
            "LABEL INIT tensor(142) torch.Size([1728])\n",
            "LABEL INIT tensor(20) torch.Size([3718])\n",
            "LABEL INIT tensor(8) torch.Size([83])\n",
            "LABEL INIT tensor(68) torch.Size([1261])\n",
            "LABEL INIT tensor(110) torch.Size([3356])\n",
            "LABEL INIT tensor(19) torch.Size([1092])\n",
            "LABEL INIT tensor(31) torch.Size([190])\n",
            "LABEL INIT tensor(129) torch.Size([591])\n",
            "LABEL INIT tensor(12) torch.Size([1276])\n",
            "LABEL INIT tensor(39) torch.Size([1139])\n",
            "LABEL INIT tensor(53) torch.Size([585])\n",
            "LABEL INIT tensor(49) torch.Size([1350])\n",
            "LABEL INIT tensor(69) torch.Size([4125])\n",
            "LABEL INIT tensor(127) torch.Size([214])\n",
            "LABEL INIT tensor(95) torch.Size([1189])\n",
            "LABEL INIT tensor(136) torch.Size([149])\n",
            "LABEL INIT tensor(143) torch.Size([2367])\n",
            "LABEL INIT tensor(38) torch.Size([2435])\n",
            "LABEL INIT tensor(11) torch.Size([323])\n",
            "LABEL INIT tensor(40) torch.Size([566])\n",
            "LABEL INIT tensor(73) torch.Size([165])\n",
            "LABEL INIT tensor(6) torch.Size([129])\n",
            "LABEL INIT tensor(47) torch.Size([302])\n",
            "LABEL INIT tensor(60) torch.Size([33])\n",
            "LABEL INIT tensor(83) torch.Size([111])\n",
            "LABEL INIT tensor(61) torch.Size([25])\n",
            "LABEL INIT tensor(46) torch.Size([50])\n",
            "LABEL INIT tensor(71) torch.Size([31])\n",
            "LABEL INIT tensor(103) torch.Size([143])\n",
            "LABEL INIT tensor(22) torch.Size([7])\n",
            "LABEL INIT tensor(21) torch.Size([7])\n",
            "LABEL INIT tensor(111) torch.Size([1])\n",
            "LABEL tensor(3) 243942\n",
            "TRAINING MODEL  1  /  150\n",
            "2023-07-27 10:02:29,671 - learnergy.core.model — DEBUG — Device: cuda.\n",
            "HERE SUBSET STATS -5.5313163 9.183313 0.5131099 0.5491289\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "| ID | GPU | MEM |\n",
            "------------------\n",
            "|  0 |  0% | 10% |\n",
            "  0% 0/2439 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "100% 2439/2439 [00:25<00:00, 94.12it/s] \n",
            "Epoch 1/15 STDEV  0.001\n",
            "100% 2439/2439 [00:45<00:00, 53.74it/s]\n",
            "2023-07-27 10:03:41,214 - rbm_models.clust_dbn — INFO — LOSS: 1.369103\n",
            "Epoch 2/15 STDEV  0.0001\n",
            "100% 2439/2439 [00:42<00:00, 57.27it/s]\n",
            "2023-07-27 10:04:23,802 - rbm_models.clust_dbn — INFO — LOSS: 1.018491\n",
            "Epoch 3/15 STDEV  1e-05\n",
            "100% 2439/2439 [00:43<00:00, 56.28it/s]\n",
            "2023-07-27 10:05:07,142 - rbm_models.clust_dbn — INFO — LOSS: 0.971884\n",
            "Epoch 4/15 STDEV  1e-06\n",
            "100% 2439/2439 [00:45<00:00, 53.11it/s]\n",
            "2023-07-27 10:05:53,064 - rbm_models.clust_dbn — INFO — LOSS: 0.943445\n",
            "Epoch 5/15 STDEV  0.0\n",
            "100% 2439/2439 [00:34<00:00, 70.23it/s]\n",
            "2023-07-27 10:06:27,795 - rbm_models.clust_dbn — INFO — LOSS: 0.912221\n",
            "Epoch 6/15 STDEV  0.001\n",
            "100% 2439/2439 [00:44<00:00, 54.87it/s]\n",
            "2023-07-27 10:07:12,246 - rbm_models.clust_dbn — INFO — LOSS: 0.803576\n",
            "Epoch 7/15 STDEV  0.0001\n",
            "100% 2439/2439 [00:43<00:00, 56.67it/s]\n",
            "2023-07-27 10:07:55,283 - rbm_models.clust_dbn — INFO — LOSS: 0.684529\n",
            "Epoch 8/15 STDEV  1e-05\n",
            "100% 2439/2439 [00:42<00:00, 56.79it/s]\n",
            "2023-07-27 10:08:38,235 - rbm_models.clust_dbn — INFO — LOSS: 0.649946\n",
            "Epoch 9/15 STDEV  1e-06\n",
            "100% 2439/2439 [00:42<00:00, 57.12it/s]\n",
            "2023-07-27 10:09:20,938 - rbm_models.clust_dbn — INFO — LOSS: 0.627968\n",
            "Epoch 10/15 STDEV  0.0\n",
            "100% 2439/2439 [00:33<00:00, 73.84it/s]\n",
            "2023-07-27 10:09:53,972 - rbm_models.clust_dbn — INFO — LOSS: 0.612500\n",
            "Epoch 11/15 STDEV  0.001\n",
            "100% 2439/2439 [00:42<00:00, 57.92it/s]\n",
            "2023-07-27 10:10:36,082 - rbm_models.clust_dbn — INFO — LOSS: 0.601558\n",
            "Epoch 12/15 STDEV  0.0001\n",
            "100% 2439/2439 [00:41<00:00, 58.15it/s]\n",
            "2023-07-27 10:11:18,025 - rbm_models.clust_dbn — INFO — LOSS: 0.593433\n",
            "Epoch 13/15 STDEV  1e-05\n",
            "100% 2439/2439 [00:41<00:00, 58.52it/s]\n",
            "2023-07-27 10:11:59,701 - rbm_models.clust_dbn — INFO — LOSS: 0.587428\n",
            "Epoch 14/15 STDEV  1e-06\n",
            "100% 2439/2439 [00:42<00:00, 57.21it/s]\n",
            "2023-07-27 10:12:42,333 - rbm_models.clust_dbn — INFO — LOSS: 0.583448\n",
            "Epoch 15/15 STDEV  0.0\n",
            "100% 2439/2439 [00:32<00:00, 75.83it/s]\n",
            "2023-07-27 10:13:14,498 - rbm_models.clust_dbn — INFO — LOSS: 0.580337\n",
            "LABEL tensor(4) 81476\n",
            "TRAINING MODEL  2  /  150\n",
            "2023-07-27 10:13:14,499 - learnergy.core.model — DEBUG — Device: cuda.\n",
            "HERE SUBSET STATS -8.9276705 7.9066854 0.3164332 0.532545\n",
            "| ID | GPU | MEM |\n",
            "------------------\n",
            "|  0 |  0% | 11% |\n",
            "  0% 0/814 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "100% 814/814 [00:06<00:00, 127.54it/s]\n",
            "Epoch 1/15 STDEV  0.001\n",
            "100% 814/814 [00:14<00:00, 54.57it/s]\n",
            "2023-07-27 10:13:35,886 - rbm_models.clust_dbn — INFO — LOSS: 1.808588\n",
            "Epoch 2/15 STDEV  0.0001\n",
            "100% 814/814 [00:15<00:00, 53.91it/s]\n",
            "2023-07-27 10:13:50,985 - rbm_models.clust_dbn — INFO — LOSS: 1.171960\n",
            "Epoch 3/15 STDEV  1e-05\n",
            "100% 814/814 [00:15<00:00, 53.13it/s]\n",
            "2023-07-27 10:14:06,306 - rbm_models.clust_dbn — INFO — LOSS: 1.041315\n",
            "Epoch 4/15 STDEV  1e-06\n",
            "100% 814/814 [00:15<00:00, 52.12it/s]\n",
            "2023-07-27 10:14:21,926 - rbm_models.clust_dbn — INFO — LOSS: 0.998505\n",
            "Epoch 5/15 STDEV  0.0\n",
            "100% 814/814 [00:11<00:00, 72.36it/s]\n",
            "2023-07-27 10:14:33,177 - rbm_models.clust_dbn — INFO — LOSS: 0.962976\n",
            "Epoch 6/15 STDEV  0.001\n",
            "100% 814/814 [00:14<00:00, 56.28it/s]\n",
            "2023-07-27 10:14:47,642 - rbm_models.clust_dbn — INFO — LOSS: 0.925004\n",
            "Epoch 7/15 STDEV  0.0001\n",
            "100% 814/814 [00:15<00:00, 53.72it/s]\n",
            "2023-07-27 10:15:02,796 - rbm_models.clust_dbn — INFO — LOSS: 0.883181\n",
            "Epoch 8/15 STDEV  1e-05\n",
            "100% 814/814 [00:14<00:00, 56.01it/s]\n",
            "2023-07-27 10:15:17,331 - rbm_models.clust_dbn — INFO — LOSS: 0.824006\n",
            "Epoch 9/15 STDEV  1e-06\n",
            "100% 814/814 [00:14<00:00, 55.32it/s]\n",
            "2023-07-27 10:15:32,048 - rbm_models.clust_dbn — INFO — LOSS: 0.774821\n",
            "Epoch 10/15 STDEV  0.0\n",
            "100% 814/814 [00:11<00:00, 73.50it/s]\n",
            "2023-07-27 10:15:43,124 - rbm_models.clust_dbn — INFO — LOSS: 0.747784\n",
            "Epoch 11/15 STDEV  0.001\n",
            "100% 814/814 [00:14<00:00, 55.58it/s]\n",
            "2023-07-27 10:15:57,771 - rbm_models.clust_dbn — INFO — LOSS: 0.727897\n",
            "Epoch 12/15 STDEV  0.0001\n",
            "100% 814/814 [00:14<00:00, 54.47it/s]\n",
            "2023-07-27 10:16:12,716 - rbm_models.clust_dbn — INFO — LOSS: 0.712402\n",
            "Epoch 13/15 STDEV  1e-05\n",
            "100% 814/814 [00:15<00:00, 53.77it/s]\n",
            "2023-07-27 10:16:27,855 - rbm_models.clust_dbn — INFO — LOSS: 0.698592\n",
            "Epoch 14/15 STDEV  1e-06\n",
            "100% 814/814 [00:15<00:00, 53.08it/s]\n",
            "2023-07-27 10:16:43,193 - rbm_models.clust_dbn — INFO — LOSS: 0.681596\n",
            "Epoch 15/15 STDEV  0.0\n",
            "100% 814/814 [00:11<00:00, 70.41it/s]\n",
            "2023-07-27 10:16:54,756 - rbm_models.clust_dbn — INFO — LOSS: 0.667576\n",
            "LABEL tensor(16) 325399\n",
            "TRAINING MODEL  3  /  150\n",
            "2023-07-27 10:16:54,757 - learnergy.core.model — DEBUG — Device: cuda.\n",
            "HERE SUBSET STATS -5.288575 7.4245563 0.4405613 0.5002945\n",
            "| ID | GPU | MEM |\n",
            "------------------\n",
            "|  0 |  0% | 11% |\n",
            "  0% 0/3253 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "100% 3253/3253 [00:21<00:00, 149.85it/s]\n",
            "Epoch 1/15 STDEV  0.001\n",
            "100% 3253/3253 [00:58<00:00, 55.92it/s]\n",
            "2023-07-27 10:18:14,906 - rbm_models.clust_dbn — INFO — LOSS: 1.293151\n",
            "Epoch 2/15 STDEV  0.0001\n",
            "100% 3253/3253 [00:55<00:00, 58.44it/s]\n",
            "2023-07-27 10:19:10,573 - rbm_models.clust_dbn — INFO — LOSS: 0.977736\n",
            "Epoch 3/15 STDEV  1e-05\n",
            "100% 3253/3253 [00:57<00:00, 56.12it/s]\n",
            "2023-07-27 10:20:08,543 - rbm_models.clust_dbn — INFO — LOSS: 0.947261\n",
            "Epoch 4/15 STDEV  1e-06\n",
            "100% 3253/3253 [00:58<00:00, 55.93it/s]\n",
            "2023-07-27 10:21:06,705 - rbm_models.clust_dbn — INFO — LOSS: 0.933244\n",
            "Epoch 5/15 STDEV  0.0\n",
            "100% 3253/3253 [00:43<00:00, 74.03it/s]\n",
            "2023-07-27 10:21:50,645 - rbm_models.clust_dbn — INFO — LOSS: 0.923586\n",
            "Epoch 6/15 STDEV  0.001\n",
            "100% 3253/3253 [00:58<00:00, 55.84it/s]\n",
            "2023-07-27 10:22:48,901 - rbm_models.clust_dbn — INFO — LOSS: 0.915341\n",
            "Epoch 7/15 STDEV  0.0001\n",
            "100% 3253/3253 [00:58<00:00, 55.95it/s]\n",
            "2023-07-27 10:23:47,048 - rbm_models.clust_dbn — INFO — LOSS: 0.908367\n",
            "Epoch 8/15 STDEV  1e-05\n",
            "100% 3253/3253 [00:57<00:00, 56.27it/s]\n",
            "2023-07-27 10:24:44,864 - rbm_models.clust_dbn — INFO — LOSS: 0.898658\n",
            "Epoch 9/15 STDEV  1e-06\n",
            "100% 3253/3253 [00:56<00:00, 58.02it/s]\n",
            "2023-07-27 10:25:40,937 - rbm_models.clust_dbn — INFO — LOSS: 0.873188\n",
            "Epoch 10/15 STDEV  0.0\n",
            "100% 3253/3253 [00:43<00:00, 75.08it/s]\n",
            "2023-07-27 10:26:24,267 - rbm_models.clust_dbn — INFO — LOSS: 0.692456\n",
            "Epoch 11/15 STDEV  0.001\n",
            "100% 3253/3253 [00:59<00:00, 54.43it/s]\n",
            "2023-07-27 10:27:24,030 - rbm_models.clust_dbn — INFO — LOSS: 0.633003\n",
            "Epoch 12/15 STDEV  0.0001\n",
            "100% 3253/3253 [00:58<00:00, 55.26it/s]\n",
            "2023-07-27 10:28:22,899 - rbm_models.clust_dbn — INFO — LOSS: 0.612624\n",
            "Epoch 13/15 STDEV  1e-05\n",
            "100% 3253/3253 [01:00<00:00, 53.74it/s]\n",
            "2023-07-27 10:29:23,428 - rbm_models.clust_dbn — INFO — LOSS: 0.599690\n",
            "Epoch 14/15 STDEV  1e-06\n",
            "100% 3253/3253 [00:57<00:00, 56.66it/s]\n",
            "2023-07-27 10:30:20,840 - rbm_models.clust_dbn — INFO — LOSS: 0.589776\n",
            "Epoch 15/15 STDEV  0.0\n",
            "100% 3253/3253 [00:44<00:00, 73.17it/s]\n",
            "2023-07-27 10:31:05,300 - rbm_models.clust_dbn — INFO — LOSS: 0.584023\n",
            "LABEL tensor(34) 360288\n",
            "TRAINING MODEL  4  /  150\n",
            "2023-07-27 10:31:05,301 - learnergy.core.model — DEBUG — Device: cuda.\n",
            "HERE SUBSET STATS -8.9276705 4.102459 -0.08290438 0.7577957\n",
            "| ID | GPU | MEM |\n",
            "------------------\n",
            "|  0 |  0% | 11% |\n",
            "  0% 0/3602 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "100% 3602/3602 [00:23<00:00, 152.18it/s]\n",
            "Epoch 1/15 STDEV  0.001\n",
            "100% 3602/3602 [01:01<00:00, 58.67it/s]\n",
            "2023-07-27 10:32:30,679 - rbm_models.clust_dbn — INFO — LOSS: 1.177361\n",
            "Epoch 2/15 STDEV  0.0001\n",
            "100% 3602/3602 [01:02<00:00, 57.33it/s]\n",
            "2023-07-27 10:33:33,511 - rbm_models.clust_dbn — INFO — LOSS: 0.749159\n",
            "Epoch 3/15 STDEV  1e-05\n",
            "100% 3602/3602 [01:01<00:00, 58.34it/s]\n",
            "2023-07-27 10:34:35,252 - rbm_models.clust_dbn — INFO — LOSS: 0.629809\n",
            "Epoch 4/15 STDEV  1e-06\n",
            "100% 3602/3602 [01:01<00:00, 58.34it/s]\n",
            "2023-07-27 10:35:36,991 - rbm_models.clust_dbn — INFO — LOSS: 0.591467\n",
            "Epoch 5/15 STDEV  0.0\n",
            "100% 3602/3602 [00:46<00:00, 77.98it/s]\n",
            "2023-07-27 10:36:23,184 - rbm_models.clust_dbn — INFO — LOSS: 0.574461\n",
            "Epoch 6/15 STDEV  0.001\n",
            "100% 3602/3602 [01:01<00:00, 58.46it/s]\n",
            "2023-07-27 10:37:24,795 - rbm_models.clust_dbn — INFO — LOSS: 0.565451\n",
            "Epoch 7/15 STDEV  0.0001\n",
            "100% 3602/3602 [01:01<00:00, 58.30it/s]\n",
            "2023-07-27 10:38:26,577 - rbm_models.clust_dbn — INFO — LOSS: 0.561690\n",
            "Epoch 8/15 STDEV  1e-05\n",
            "100% 3602/3602 [01:00<00:00, 59.63it/s]\n",
            "2023-07-27 10:39:26,980 - rbm_models.clust_dbn — INFO — LOSS: 0.558957\n",
            "Epoch 9/15 STDEV  1e-06\n",
            "100% 3602/3602 [01:01<00:00, 58.41it/s]\n",
            "2023-07-27 10:40:28,648 - rbm_models.clust_dbn — INFO — LOSS: 0.556667\n",
            "Epoch 10/15 STDEV  0.0\n",
            "100% 3602/3602 [00:47<00:00, 75.90it/s]\n",
            "2023-07-27 10:41:16,104 - rbm_models.clust_dbn — INFO — LOSS: 0.555344\n",
            "Epoch 11/15 STDEV  0.001\n",
            "100% 3602/3602 [01:02<00:00, 57.31it/s]\n",
            "2023-07-27 10:42:18,959 - rbm_models.clust_dbn — INFO — LOSS: 0.553126\n",
            "Epoch 12/15 STDEV  0.0001\n",
            "100% 3602/3602 [01:01<00:00, 58.58it/s]\n",
            "2023-07-27 10:43:20,450 - rbm_models.clust_dbn — INFO — LOSS: 0.552404\n",
            "Epoch 13/15 STDEV  1e-05\n",
            "100% 3602/3602 [01:01<00:00, 58.29it/s]\n",
            "2023-07-27 10:44:22,245 - rbm_models.clust_dbn — INFO — LOSS: 0.551514\n",
            "Epoch 14/15 STDEV  1e-06\n",
            "100% 3602/3602 [01:01<00:00, 58.62it/s]\n",
            "2023-07-27 10:45:23,698 - rbm_models.clust_dbn — INFO — LOSS: 0.550533\n",
            "Epoch 15/15 STDEV  0.0\n",
            "100% 3602/3602 [00:46<00:00, 77.86it/s]\n",
            "2023-07-27 10:46:09,964 - rbm_models.clust_dbn — INFO — LOSS: 0.549490\n",
            "LABEL tensor(41) 389331\n",
            "TRAINING MODEL  5  /  150\n",
            "2023-07-27 10:46:09,965 - learnergy.core.model — DEBUG — Device: cuda.\n",
            "HERE SUBSET STATS -3.233697 7.385473 0.22269943 0.5356206\n",
            "| ID | GPU | MEM |\n",
            "------------------\n",
            "|  0 |  0% | 12% |\n",
            "  0% 0/3893 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "100% 3893/3893 [00:26<00:00, 148.94it/s]\n",
            "Epoch 1/15 STDEV  0.001\n",
            "100% 3893/3893 [01:05<00:00, 59.29it/s]\n",
            "2023-07-27 10:47:42,070 - rbm_models.clust_dbn — INFO — LOSS: 1.208974\n",
            "Epoch 2/15 STDEV  0.0001\n",
            "100% 3893/3893 [01:06<00:00, 58.22it/s]\n",
            "2023-07-27 10:48:48,939 - rbm_models.clust_dbn — INFO — LOSS: 0.915502\n",
            "Epoch 3/15 STDEV  1e-05\n",
            "100% 3893/3893 [01:07<00:00, 58.03it/s]\n",
            "2023-07-27 10:49:56,029 - rbm_models.clust_dbn — INFO — LOSS: 0.744588\n",
            "Epoch 4/15 STDEV  1e-06\n",
            "100% 3893/3893 [01:13<00:00, 52.95it/s]\n",
            "2023-07-27 10:51:09,555 - rbm_models.clust_dbn — INFO — LOSS: 0.667947\n",
            "Epoch 5/15 STDEV  0.0\n",
            "100% 3893/3893 [00:53<00:00, 73.27it/s]\n",
            "2023-07-27 10:52:02,687 - rbm_models.clust_dbn — INFO — LOSS: 0.626763\n",
            "Epoch 6/15 STDEV  0.001\n",
            "100% 3893/3893 [01:12<00:00, 53.88it/s]\n",
            "2023-07-27 10:53:14,943 - rbm_models.clust_dbn — INFO — LOSS: 0.604931\n",
            "Epoch 7/15 STDEV  0.0001\n",
            "100% 3893/3893 [01:06<00:00, 58.82it/s]\n",
            "2023-07-27 10:54:21,135 - rbm_models.clust_dbn — INFO — LOSS: 0.592671\n",
            "Epoch 8/15 STDEV  1e-05\n",
            "100% 3893/3893 [01:07<00:00, 57.95it/s]\n",
            "2023-07-27 10:55:28,313 - rbm_models.clust_dbn — INFO — LOSS: 0.585460\n",
            "Epoch 9/15 STDEV  1e-06\n",
            "100% 3893/3893 [01:06<00:00, 58.17it/s]\n",
            "2023-07-27 10:56:35,239 - rbm_models.clust_dbn — INFO — LOSS: 0.581326\n",
            "Epoch 10/15 STDEV  0.0\n",
            "100% 3893/3893 [00:49<00:00, 78.15it/s]\n",
            "2023-07-27 10:57:25,053 - rbm_models.clust_dbn — INFO — LOSS: 0.578548\n",
            "Epoch 11/15 STDEV  0.001\n",
            "100% 3893/3893 [01:06<00:00, 58.61it/s]\n",
            "2023-07-27 10:58:31,475 - rbm_models.clust_dbn — INFO — LOSS: 0.577098\n",
            "Epoch 12/15 STDEV  0.0001\n",
            "100% 3893/3893 [01:07<00:00, 57.62it/s]\n",
            "2023-07-27 10:59:39,043 - rbm_models.clust_dbn — INFO — LOSS: 0.575198\n",
            "Epoch 13/15 STDEV  1e-05\n",
            "100% 3893/3893 [01:07<00:00, 57.75it/s]\n",
            "2023-07-27 11:00:46,462 - rbm_models.clust_dbn — INFO — LOSS: 0.574207\n",
            "Epoch 14/15 STDEV  1e-06\n",
            "100% 3893/3893 [01:07<00:00, 57.72it/s]\n",
            "2023-07-27 11:01:53,908 - rbm_models.clust_dbn — INFO — LOSS: 0.574054\n",
            "Epoch 15/15 STDEV  0.0\n",
            "100% 3893/3893 [00:50<00:00, 77.36it/s]\n",
            "2023-07-27 11:02:44,229 - rbm_models.clust_dbn — INFO — LOSS: 0.572891\n",
            "LABEL tensor(56) 8471\n",
            "TRAINING MODEL  6  /  150\n",
            "2023-07-27 11:02:44,230 - learnergy.core.model — DEBUG — Device: cuda.\n",
            "HERE SUBSET STATS -4.5952992 5.626715 -0.08388315 0.65349436\n",
            "| ID | GPU | MEM |\n",
            "------------------\n",
            "|  0 |  0% | 13% |\n",
            "  0% 0/84 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "100% 84/84 [00:01<00:00, 43.59it/s]\n",
            "Epoch 1/15 STDEV  0.001\n",
            "100% 84/84 [00:02<00:00, 30.04it/s]\n",
            "2023-07-27 11:02:48,983 - rbm_models.clust_dbn — INFO — LOSS: 3.660959\n",
            "Epoch 2/15 STDEV  0.0001\n",
            "100% 84/84 [00:02<00:00, 30.69it/s]\n",
            "2023-07-27 11:02:51,721 - rbm_models.clust_dbn — INFO — LOSS: 2.271455\n",
            "Epoch 3/15 STDEV  1e-05\n",
            "100% 84/84 [00:02<00:00, 30.69it/s]\n",
            "2023-07-27 11:02:54,459 - rbm_models.clust_dbn — INFO — LOSS: 1.858516\n",
            "Epoch 4/15 STDEV  1e-06\n",
            "100% 84/84 [00:02<00:00, 31.15it/s]\n",
            "2023-07-27 11:02:57,158 - rbm_models.clust_dbn — INFO — LOSS: 1.629216\n",
            "Epoch 5/15 STDEV  0.0\n",
            "100% 84/84 [00:02<00:00, 33.86it/s]\n",
            "2023-07-27 11:02:59,640 - rbm_models.clust_dbn — INFO — LOSS: 1.510425\n",
            "Epoch 6/15 STDEV  0.001\n",
            "100% 84/84 [00:02<00:00, 29.30it/s]\n",
            "2023-07-27 11:03:02,509 - rbm_models.clust_dbn — INFO — LOSS: 1.444138\n",
            "Epoch 7/15 STDEV  0.0001\n",
            "100% 84/84 [00:02<00:00, 30.80it/s]\n",
            "2023-07-27 11:03:05,237 - rbm_models.clust_dbn — INFO — LOSS: 1.401318\n",
            "Epoch 8/15 STDEV  1e-05\n",
            "100% 84/84 [00:02<00:00, 31.06it/s]\n",
            "2023-07-27 11:03:07,943 - rbm_models.clust_dbn — INFO — LOSS: 1.368955\n",
            "Epoch 9/15 STDEV  1e-06\n",
            "100% 84/84 [00:02<00:00, 30.99it/s]\n",
            "2023-07-27 11:03:10,655 - rbm_models.clust_dbn — INFO — LOSS: 1.341992\n",
            "Epoch 10/15 STDEV  0.0\n",
            "100% 84/84 [00:02<00:00, 34.20it/s]\n",
            "2023-07-27 11:03:13,112 - rbm_models.clust_dbn — INFO — LOSS: 1.319020\n",
            "Epoch 11/15 STDEV  0.001\n",
            "100% 84/84 [00:02<00:00, 29.37it/s]\n",
            "2023-07-27 11:03:15,974 - rbm_models.clust_dbn — INFO — LOSS: 1.303649\n",
            "Epoch 12/15 STDEV  0.0001\n",
            "100% 84/84 [00:02<00:00, 31.14it/s]\n",
            "2023-07-27 11:03:18,673 - rbm_models.clust_dbn — INFO — LOSS: 1.286047\n",
            "Epoch 13/15 STDEV  1e-05\n",
            "100% 84/84 [00:02<00:00, 31.13it/s]\n",
            "2023-07-27 11:03:21,372 - rbm_models.clust_dbn — INFO — LOSS: 1.275142\n",
            "Epoch 14/15 STDEV  1e-06\n",
            "100% 84/84 [00:02<00:00, 30.00it/s]\n",
            "2023-07-27 11:03:24,174 - rbm_models.clust_dbn — INFO — LOSS: 1.262754\n",
            "Epoch 15/15 STDEV  0.0\n",
            "100% 84/84 [00:02<00:00, 35.81it/s]\n",
            "2023-07-27 11:03:26,521 - rbm_models.clust_dbn — INFO — LOSS: 1.255298\n",
            "LABEL tensor(58) 354826\n",
            "TRAINING MODEL  7  /  150\n",
            "2023-07-27 11:03:26,522 - learnergy.core.model — DEBUG — Device: cuda.\n",
            "HERE SUBSET STATS -8.9276705 8.088976 0.13282374 0.6052909\n",
            "| ID | GPU | MEM |\n",
            "------------------\n",
            "|  0 |  0% | 13% |\n",
            "  0% 0/3548 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "100% 3548/3548 [00:23<00:00, 148.77it/s]\n",
            "Epoch 1/15 STDEV  0.001\n",
            "100% 3548/3548 [00:59<00:00, 59.39it/s]\n",
            "2023-07-27 11:04:50,396 - rbm_models.clust_dbn — INFO — LOSS: 1.241638\n",
            "Epoch 2/15 STDEV  0.0001\n",
            "100% 3548/3548 [01:01<00:00, 57.89it/s]\n",
            "2023-07-27 11:05:51,683 - rbm_models.clust_dbn — INFO — LOSS: 0.894706\n",
            "Epoch 3/15 STDEV  1e-05\n",
            "100% 3548/3548 [01:01<00:00, 57.90it/s]\n",
            "2023-07-27 11:06:52,968 - rbm_models.clust_dbn — INFO — LOSS: 0.689063\n",
            "Epoch 4/15 STDEV  1e-06\n",
            "100% 3548/3548 [01:02<00:00, 57.07it/s]\n",
            "2023-07-27 11:07:55,137 - rbm_models.clust_dbn — INFO — LOSS: 0.624373\n",
            "Epoch 5/15 STDEV  0.0\n",
            "100% 3548/3548 [00:46<00:00, 75.81it/s]\n",
            "2023-07-27 11:08:41,942 - rbm_models.clust_dbn — INFO — LOSS: 0.596714\n",
            "Epoch 6/15 STDEV  0.001\n",
            "100% 3548/3548 [01:03<00:00, 55.79it/s]\n",
            "2023-07-27 11:09:45,539 - rbm_models.clust_dbn — INFO — LOSS: 0.584116\n",
            "Epoch 7/15 STDEV  0.0001\n",
            "100% 3548/3548 [01:02<00:00, 56.44it/s]\n",
            "2023-07-27 11:10:48,402 - rbm_models.clust_dbn — INFO — LOSS: 0.577927\n",
            "Epoch 8/15 STDEV  1e-05\n",
            "100% 3548/3548 [01:02<00:00, 56.69it/s]\n",
            "2023-07-27 11:11:50,991 - rbm_models.clust_dbn — INFO — LOSS: 0.575154\n",
            "Epoch 9/15 STDEV  1e-06\n",
            "100% 3548/3548 [01:03<00:00, 55.47it/s]\n",
            "2023-07-27 11:12:54,951 - rbm_models.clust_dbn — INFO — LOSS: 0.573111\n",
            "Epoch 10/15 STDEV  0.0\n",
            "100% 3548/3548 [00:46<00:00, 76.71it/s]\n",
            "2023-07-27 11:13:41,207 - rbm_models.clust_dbn — INFO — LOSS: 0.571806\n",
            "Epoch 11/15 STDEV  0.001\n",
            "100% 3548/3548 [01:04<00:00, 54.65it/s]\n",
            "2023-07-27 11:14:46,128 - rbm_models.clust_dbn — INFO — LOSS: 0.569974\n",
            "Epoch 12/15 STDEV  0.0001\n",
            "100% 3548/3548 [01:07<00:00, 52.67it/s]\n",
            "2023-07-27 11:15:53,498 - rbm_models.clust_dbn — INFO — LOSS: 0.569052\n",
            "Epoch 13/15 STDEV  1e-05\n",
            "100% 3548/3548 [01:04<00:00, 55.21it/s]\n",
            "2023-07-27 11:16:57,763 - rbm_models.clust_dbn — INFO — LOSS: 0.568382\n",
            "Epoch 14/15 STDEV  1e-06\n",
            "100% 3548/3548 [01:05<00:00, 54.45it/s]\n",
            "2023-07-27 11:18:02,920 - rbm_models.clust_dbn — INFO — LOSS: 0.567522\n",
            "Epoch 15/15 STDEV  0.0\n",
            "100% 3548/3548 [00:46<00:00, 76.88it/s]\n",
            "2023-07-27 11:18:49,070 - rbm_models.clust_dbn — INFO — LOSS: 0.567102\n",
            "LABEL tensor(64) 116221\n",
            "TRAINING MODEL  8  /  150\n",
            "2023-07-27 11:18:49,071 - learnergy.core.model — DEBUG — Device: cuda.\n",
            "HERE SUBSET STATS -8.9276705 8.284393 0.44557112 0.7455842\n",
            "| ID | GPU | MEM |\n",
            "------------------\n",
            "|  0 |  0% | 14% |\n",
            "  0% 0/1162 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "100% 1162/1162 [00:08<00:00, 134.92it/s]\n",
            "Epoch 1/15 STDEV  0.001\n",
            "100% 1162/1162 [00:20<00:00, 55.79it/s]\n",
            "2023-07-27 11:19:18,628 - rbm_models.clust_dbn — INFO — LOSS: 1.751146\n",
            "Epoch 2/15 STDEV  0.0001\n",
            "100% 1162/1162 [00:20<00:00, 55.98it/s]\n",
            "2023-07-27 11:19:39,385 - rbm_models.clust_dbn — INFO — LOSS: 1.158121\n",
            "Epoch 3/15 STDEV  1e-05\n",
            "100% 1162/1162 [00:20<00:00, 56.39it/s]\n",
            "2023-07-27 11:19:59,994 - rbm_models.clust_dbn — INFO — LOSS: 1.043968\n",
            "Epoch 4/15 STDEV  1e-06\n",
            "100% 1162/1162 [00:20<00:00, 56.09it/s]\n",
            "2023-07-27 11:20:20,712 - rbm_models.clust_dbn — INFO — LOSS: 1.001891\n",
            "Epoch 5/15 STDEV  0.0\n",
            "100% 1162/1162 [00:15<00:00, 73.67it/s]\n",
            "2023-07-27 11:20:36,488 - rbm_models.clust_dbn — INFO — LOSS: 0.970839\n",
            "Epoch 6/15 STDEV  0.001\n",
            "100% 1162/1162 [00:20<00:00, 55.87it/s]\n",
            "2023-07-27 11:20:57,287 - rbm_models.clust_dbn — INFO — LOSS: 0.946647\n",
            "Epoch 7/15 STDEV  0.0001\n",
            "100% 1162/1162 [00:21<00:00, 54.55it/s]\n",
            "2023-07-27 11:21:18,591 - rbm_models.clust_dbn — INFO — LOSS: 0.917753\n",
            "Epoch 8/15 STDEV  1e-05\n",
            "100% 1162/1162 [00:20<00:00, 56.22it/s]\n",
            "2023-07-27 11:21:39,262 - rbm_models.clust_dbn — INFO — LOSS: 0.874745\n",
            "Epoch 9/15 STDEV  1e-06\n",
            "100% 1162/1162 [00:21<00:00, 54.90it/s]\n",
            "2023-07-27 11:22:00,429 - rbm_models.clust_dbn — INFO — LOSS: 0.829952\n",
            "Epoch 10/15 STDEV  0.0\n",
            "100% 1162/1162 [00:16<00:00, 70.02it/s]\n",
            "2023-07-27 11:22:17,025 - rbm_models.clust_dbn — INFO — LOSS: 0.804092\n",
            "Epoch 11/15 STDEV  0.001\n",
            "100% 1162/1162 [00:22<00:00, 52.29it/s]\n",
            "2023-07-27 11:22:39,250 - rbm_models.clust_dbn — INFO — LOSS: 0.781924\n",
            "Epoch 12/15 STDEV  0.0001\n",
            "100% 1162/1162 [00:21<00:00, 54.56it/s]\n",
            "2023-07-27 11:23:00,548 - rbm_models.clust_dbn — INFO — LOSS: 0.760025\n",
            "Epoch 13/15 STDEV  1e-05\n",
            "100% 1162/1162 [00:20<00:00, 56.03it/s]\n",
            "2023-07-27 11:23:21,288 - rbm_models.clust_dbn — INFO — LOSS: 0.731745\n",
            "Epoch 14/15 STDEV  1e-06\n",
            "100% 1162/1162 [00:20<00:00, 55.48it/s]\n",
            "2023-07-27 11:23:42,232 - rbm_models.clust_dbn — INFO — LOSS: 0.706781\n",
            "Epoch 15/15 STDEV  0.0\n",
            "100% 1162/1162 [00:15<00:00, 72.85it/s]\n",
            "2023-07-27 11:23:58,183 - rbm_models.clust_dbn — INFO — LOSS: 0.688217\n",
            "LABEL tensor(65) 12290\n",
            "TRAINING MODEL  9  /  150\n",
            "2023-07-27 11:23:58,184 - learnergy.core.model — DEBUG — Device: cuda.\n",
            "HERE SUBSET STATS -7.5660677 11.020238 -0.14091402 0.8550824\n",
            "| ID | GPU | MEM |\n",
            "------------------\n",
            "|  0 |  0% | 14% |\n",
            "  0% 0/122 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "100% 122/122 [00:02<00:00, 57.01it/s] \n",
            "Epoch 1/15 STDEV  0.001\n",
            "100% 122/122 [00:03<00:00, 36.39it/s]\n",
            "2023-07-27 11:24:03,708 - rbm_models.clust_dbn — INFO — LOSS: 3.235890\n",
            "Epoch 2/15 STDEV  0.0001\n",
            "100% 122/122 [00:03<00:00, 35.82it/s]\n",
            "2023-07-27 11:24:07,115 - rbm_models.clust_dbn — INFO — LOSS: 1.822483\n",
            "Epoch 3/15 STDEV  1e-05\n",
            "100% 122/122 [00:03<00:00, 34.41it/s]\n",
            "2023-07-27 11:24:10,662 - rbm_models.clust_dbn — INFO — LOSS: 1.522911\n",
            "Epoch 4/15 STDEV  1e-06\n",
            "100% 122/122 [00:03<00:00, 34.66it/s]\n",
            "2023-07-27 11:24:14,184 - rbm_models.clust_dbn — INFO — LOSS: 1.408217\n",
            "Epoch 5/15 STDEV  0.0\n",
            "100% 122/122 [00:02<00:00, 43.07it/s]\n",
            "2023-07-27 11:24:17,018 - rbm_models.clust_dbn — INFO — LOSS: 1.303046\n",
            "Epoch 6/15 STDEV  0.001\n",
            "100% 122/122 [00:03<00:00, 35.93it/s]\n",
            "2023-07-27 11:24:20,415 - rbm_models.clust_dbn — INFO — LOSS: 1.212377\n",
            "Epoch 7/15 STDEV  0.0001\n",
            "100% 122/122 [00:03<00:00, 35.42it/s]\n",
            "2023-07-27 11:24:23,861 - rbm_models.clust_dbn — INFO — LOSS: 1.150798\n",
            "Epoch 8/15 STDEV  1e-05\n",
            "100% 122/122 [00:03<00:00, 34.47it/s]\n",
            "2023-07-27 11:24:27,401 - rbm_models.clust_dbn — INFO — LOSS: 1.108139\n",
            "Epoch 9/15 STDEV  1e-06\n",
            "100% 122/122 [00:03<00:00, 35.82it/s]\n",
            "2023-07-27 11:24:30,808 - rbm_models.clust_dbn — INFO — LOSS: 1.082069\n",
            "Epoch 10/15 STDEV  0.0\n",
            "100% 122/122 [00:02<00:00, 42.93it/s]\n",
            "2023-07-27 11:24:33,651 - rbm_models.clust_dbn — INFO — LOSS: 1.061975\n",
            "Epoch 11/15 STDEV  0.001\n",
            "100% 122/122 [00:03<00:00, 36.57it/s]\n",
            "2023-07-27 11:24:36,989 - rbm_models.clust_dbn — INFO — LOSS: 1.043641\n",
            "Epoch 12/15 STDEV  0.0001\n",
            "100% 122/122 [00:03<00:00, 33.61it/s]\n",
            "2023-07-27 11:24:40,621 - rbm_models.clust_dbn — INFO — LOSS: 1.030201\n",
            "Epoch 13/15 STDEV  1e-05\n",
            "100% 122/122 [00:03<00:00, 35.00it/s]\n",
            "2023-07-27 11:24:44,108 - rbm_models.clust_dbn — INFO — LOSS: 1.014911\n",
            "Epoch 14/15 STDEV  1e-06\n",
            "100% 122/122 [00:03<00:00, 36.74it/s]\n",
            "2023-07-27 11:24:47,430 - rbm_models.clust_dbn — INFO — LOSS: 1.004800\n",
            "Epoch 15/15 STDEV  0.0\n",
            "100% 122/122 [00:02<00:00, 43.11it/s]\n",
            "2023-07-27 11:24:50,261 - rbm_models.clust_dbn — INFO — LOSS: 0.992037\n",
            "LABEL tensor(74) 56664\n",
            "TRAINING MODEL  10  /  150\n",
            "2023-07-27 11:24:50,262 - learnergy.core.model — DEBUG — Device: cuda.\n",
            "HERE SUBSET STATS -7.412559 9.183313 0.32492906 0.7860659\n",
            "| ID | GPU | MEM |\n",
            "------------------\n",
            "|  0 |  0% | 14% |\n",
            "  0% 0/566 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "100% 566/566 [00:05<00:00, 112.05it/s]\n",
            "Epoch 1/15 STDEV  0.001\n",
            "100% 566/566 [00:10<00:00, 52.43it/s]\n",
            "2023-07-27 11:25:06,171 - rbm_models.clust_dbn — INFO — LOSS: 2.070707\n",
            "Epoch 2/15 STDEV  0.0001\n",
            "100% 566/566 [00:10<00:00, 51.70it/s]\n",
            "2023-07-27 11:25:17,121 - rbm_models.clust_dbn — INFO — LOSS: 1.346245\n",
            "Epoch 3/15 STDEV  1e-05\n",
            "100% 566/566 [00:10<00:00, 51.78it/s]\n",
            "2023-07-27 11:25:28,052 - rbm_models.clust_dbn — INFO — LOSS: 1.181445\n",
            "Epoch 4/15 STDEV  1e-06\n",
            "100% 566/566 [00:10<00:00, 52.32it/s]\n",
            "2023-07-27 11:25:38,871 - rbm_models.clust_dbn — INFO — LOSS: 1.031489\n",
            "Epoch 5/15 STDEV  0.0\n",
            "100% 566/566 [00:08<00:00, 66.80it/s]\n",
            "2023-07-27 11:25:47,345 - rbm_models.clust_dbn — INFO — LOSS: 1.007575\n",
            "Epoch 6/15 STDEV  0.001\n",
            "100% 566/566 [00:11<00:00, 50.81it/s]\n",
            "2023-07-27 11:25:58,486 - rbm_models.clust_dbn — INFO — LOSS: 0.991602\n",
            "Epoch 7/15 STDEV  0.0001\n",
            "100% 566/566 [00:11<00:00, 51.10it/s]\n",
            "2023-07-27 11:26:09,565 - rbm_models.clust_dbn — INFO — LOSS: 0.978304\n",
            "Epoch 8/15 STDEV  1e-05\n",
            "100% 566/566 [00:11<00:00, 51.43it/s]\n",
            "2023-07-27 11:26:20,570 - rbm_models.clust_dbn — INFO — LOSS: 0.967171\n",
            "Epoch 9/15 STDEV  1e-06\n",
            "100% 566/566 [00:11<00:00, 50.73it/s]\n",
            "2023-07-27 11:26:31,730 - rbm_models.clust_dbn — INFO — LOSS: 0.959526\n",
            "Epoch 10/15 STDEV  0.0\n",
            "100% 566/566 [00:08<00:00, 64.26it/s]\n",
            "2023-07-27 11:26:40,540 - rbm_models.clust_dbn — INFO — LOSS: 0.951558\n",
            "Epoch 11/15 STDEV  0.001\n",
            "100% 566/566 [00:10<00:00, 52.33it/s]\n",
            "2023-07-27 11:26:51,357 - rbm_models.clust_dbn — INFO — LOSS: 0.945773\n",
            "Epoch 12/15 STDEV  0.0001\n",
            "100% 566/566 [00:10<00:00, 52.24it/s]\n",
            "2023-07-27 11:27:02,192 - rbm_models.clust_dbn — INFO — LOSS: 0.940978\n",
            "Epoch 13/15 STDEV  1e-05\n",
            "100% 566/566 [00:11<00:00, 50.82it/s]\n",
            "2023-07-27 11:27:13,331 - rbm_models.clust_dbn — INFO — LOSS: 0.936201\n",
            "Epoch 14/15 STDEV  1e-06\n",
            "100% 566/566 [00:11<00:00, 50.57it/s]\n",
            "2023-07-27 11:27:24,525 - rbm_models.clust_dbn — INFO — LOSS: 0.931705\n",
            "Epoch 15/15 STDEV  0.0\n",
            "100% 566/566 [00:08<00:00, 68.20it/s]\n",
            "2023-07-27 11:27:32,825 - rbm_models.clust_dbn — INFO — LOSS: 0.927839\n",
            "LABEL tensor(75) 28113\n",
            "TRAINING MODEL  11  /  150\n",
            "2023-07-27 11:27:32,826 - learnergy.core.model — DEBUG — Device: cuda.\n",
            "HERE SUBSET STATS -2.7762368 6.721053 0.41082278 0.54068166\n",
            "| ID | GPU | MEM |\n",
            "------------------\n",
            "|  0 |  3% | 14% |\n",
            "  0% 0/281 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "100% 281/281 [00:03<00:00, 87.64it/s] \n",
            "Epoch 1/15 STDEV  0.001\n",
            "100% 281/281 [00:06<00:00, 45.61it/s]\n",
            "2023-07-27 11:27:42,238 - rbm_models.clust_dbn — INFO — LOSS: 2.445690\n",
            "Epoch 2/15 STDEV  0.0001\n",
            "100% 281/281 [00:05<00:00, 46.86it/s]\n",
            "2023-07-27 11:27:48,236 - rbm_models.clust_dbn — INFO — LOSS: 1.555886\n",
            "Epoch 3/15 STDEV  1e-05\n",
            "100% 281/281 [00:06<00:00, 44.35it/s]\n",
            "2023-07-27 11:27:54,573 - rbm_models.clust_dbn — INFO — LOSS: 1.427525\n",
            "Epoch 4/15 STDEV  1e-06\n",
            "100% 281/281 [00:05<00:00, 47.09it/s]\n",
            "2023-07-27 11:28:00,542 - rbm_models.clust_dbn — INFO — LOSS: 1.352623\n",
            "Epoch 5/15 STDEV  0.0\n",
            "100% 281/281 [00:05<00:00, 55.83it/s]\n",
            "2023-07-27 11:28:05,577 - rbm_models.clust_dbn — INFO — LOSS: 1.273097\n",
            "Epoch 6/15 STDEV  0.001\n",
            "100% 281/281 [00:06<00:00, 45.76it/s]\n",
            "2023-07-27 11:28:11,718 - rbm_models.clust_dbn — INFO — LOSS: 1.172754\n",
            "Epoch 7/15 STDEV  0.0001\n",
            "100% 281/281 [00:05<00:00, 47.23it/s]\n",
            "2023-07-27 11:28:17,670 - rbm_models.clust_dbn — INFO — LOSS: 1.108952\n",
            "Epoch 8/15 STDEV  1e-05\n",
            "100% 281/281 [00:06<00:00, 44.03it/s]\n",
            "2023-07-27 11:28:24,053 - rbm_models.clust_dbn — INFO — LOSS: 1.080889\n",
            "Epoch 9/15 STDEV  1e-06\n",
            "100% 281/281 [00:05<00:00, 47.19it/s]\n",
            "2023-07-27 11:28:30,010 - rbm_models.clust_dbn — INFO — LOSS: 1.060403\n",
            "Epoch 10/15 STDEV  0.0\n",
            "100% 281/281 [00:04<00:00, 57.11it/s]\n",
            "2023-07-27 11:28:34,931 - rbm_models.clust_dbn — INFO — LOSS: 1.044965\n",
            "Epoch 11/15 STDEV  0.001\n",
            "100% 281/281 [00:06<00:00, 45.75it/s]\n",
            "2023-07-27 11:28:41,075 - rbm_models.clust_dbn — INFO — LOSS: 1.031335\n",
            "Epoch 12/15 STDEV  0.0001\n",
            "100% 281/281 [00:05<00:00, 47.14it/s]\n",
            "2023-07-27 11:28:47,037 - rbm_models.clust_dbn — INFO — LOSS: 1.020069\n",
            "Epoch 13/15 STDEV  1e-05\n",
            "100% 281/281 [00:06<00:00, 45.77it/s]\n",
            "2023-07-27 11:28:53,178 - rbm_models.clust_dbn — INFO — LOSS: 1.010124\n",
            "Epoch 14/15 STDEV  1e-06\n",
            "100% 281/281 [00:05<00:00, 47.55it/s]\n",
            "2023-07-27 11:28:59,089 - rbm_models.clust_dbn — INFO — LOSS: 1.004933\n",
            "Epoch 15/15 STDEV  0.0\n",
            "100% 281/281 [00:04<00:00, 56.95it/s]\n",
            "2023-07-27 11:29:04,025 - rbm_models.clust_dbn — INFO — LOSS: 0.997033\n",
            "LABEL tensor(78) 97056\n",
            "TRAINING MODEL  12  /  150\n",
            "2023-07-27 11:29:04,026 - learnergy.core.model — DEBUG — Device: cuda.\n",
            "HERE SUBSET STATS -4.5952992 6.877387 0.31993932 0.6590906\n",
            "| ID | GPU | MEM |\n",
            "------------------\n",
            "|  0 |  0% | 14% |\n",
            "  0% 0/970 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "100% 970/970 [00:07<00:00, 128.71it/s]\n",
            "Epoch 1/15 STDEV  0.001\n",
            "100% 970/970 [00:17<00:00, 55.55it/s]\n",
            "2023-07-27 11:29:29,131 - rbm_models.clust_dbn — INFO — LOSS: 1.737232\n",
            "Epoch 2/15 STDEV  0.0001\n",
            "100% 970/970 [00:17<00:00, 55.13it/s]\n",
            "2023-07-27 11:29:46,728 - rbm_models.clust_dbn — INFO — LOSS: 1.145288\n",
            "Epoch 3/15 STDEV  1e-05\n",
            "100% 970/970 [00:17<00:00, 54.46it/s]\n",
            "2023-07-27 11:30:04,542 - rbm_models.clust_dbn — INFO — LOSS: 1.074944\n",
            "Epoch 4/15 STDEV  1e-06\n",
            "100% 970/970 [00:17<00:00, 54.72it/s]\n",
            "2023-07-27 11:30:22,271 - rbm_models.clust_dbn — INFO — LOSS: 1.037697\n",
            "Epoch 5/15 STDEV  0.0\n",
            "100% 970/970 [00:13<00:00, 70.82it/s]\n",
            "2023-07-27 11:30:35,969 - rbm_models.clust_dbn — INFO — LOSS: 1.013758\n",
            "Epoch 6/15 STDEV  0.001\n",
            "100% 970/970 [00:17<00:00, 54.60it/s]\n",
            "2023-07-27 11:30:53,737 - rbm_models.clust_dbn — INFO — LOSS: 0.996568\n",
            "Epoch 7/15 STDEV  0.0001\n",
            "100% 970/970 [00:17<00:00, 54.82it/s]\n",
            "2023-07-27 11:31:11,432 - rbm_models.clust_dbn — INFO — LOSS: 0.983526\n",
            "Epoch 8/15 STDEV  1e-05\n",
            "100% 970/970 [00:17<00:00, 55.14it/s]\n",
            "2023-07-27 11:31:29,024 - rbm_models.clust_dbn — INFO — LOSS: 0.972759\n",
            "Epoch 9/15 STDEV  1e-06\n",
            "100% 970/970 [00:18<00:00, 53.50it/s]\n",
            "2023-07-27 11:31:47,156 - rbm_models.clust_dbn — INFO — LOSS: 0.966259\n",
            "Epoch 10/15 STDEV  0.0\n",
            "100% 970/970 [00:13<00:00, 71.78it/s]\n",
            "2023-07-27 11:32:00,671 - rbm_models.clust_dbn — INFO — LOSS: 0.960308\n",
            "Epoch 11/15 STDEV  0.001\n",
            "100% 970/970 [00:17<00:00, 54.90it/s]\n",
            "2023-07-27 11:32:18,342 - rbm_models.clust_dbn — INFO — LOSS: 0.954816\n",
            "Epoch 12/15 STDEV  0.0001\n",
            "100% 970/970 [00:17<00:00, 54.04it/s]\n",
            "2023-07-27 11:32:36,294 - rbm_models.clust_dbn — INFO — LOSS: 0.949924\n",
            "Epoch 13/15 STDEV  1e-05\n",
            "100% 970/970 [00:17<00:00, 55.09it/s]\n",
            "2023-07-27 11:32:53,904 - rbm_models.clust_dbn — INFO — LOSS: 0.946827\n",
            "Epoch 14/15 STDEV  1e-06\n",
            "100% 970/970 [00:17<00:00, 55.89it/s]\n",
            "2023-07-27 11:33:11,262 - rbm_models.clust_dbn — INFO — LOSS: 0.943022\n",
            "Epoch 15/15 STDEV  0.0\n",
            "100% 970/970 [00:13<00:00, 72.47it/s]\n",
            "2023-07-27 11:33:24,649 - rbm_models.clust_dbn — INFO — LOSS: 0.939335\n",
            "LABEL tensor(80) 386147\n",
            "TRAINING MODEL  13  /  150\n",
            "2023-07-27 11:33:24,650 - learnergy.core.model — DEBUG — Device: cuda.\n",
            "HERE SUBSET STATS -7.5660677 5.6657987 -0.043054387 0.7374217\n",
            "| ID | GPU | MEM |\n",
            "------------------\n",
            "|  0 |  0% | 14% |\n",
            "  0% 0/3861 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "100% 3861/3861 [00:25<00:00, 152.13it/s]\n",
            "Epoch 1/15 STDEV  0.001\n",
            "100% 3861/3861 [01:06<00:00, 57.94it/s]\n",
            "2023-07-27 11:34:56,989 - rbm_models.clust_dbn — INFO — LOSS: 1.115128\n",
            "Epoch 2/15 STDEV  0.0001\n",
            "100% 3861/3861 [01:05<00:00, 58.92it/s]\n",
            "2023-07-27 11:36:02,524 - rbm_models.clust_dbn — INFO — LOSS: 0.700904\n",
            "Epoch 3/15 STDEV  1e-05\n",
            "100% 3861/3861 [01:06<00:00, 57.83it/s]\n",
            "2023-07-27 11:37:09,284 - rbm_models.clust_dbn — INFO — LOSS: 0.598627\n",
            "Epoch 4/15 STDEV  1e-06\n",
            "100% 3861/3861 [01:10<00:00, 54.74it/s]\n",
            "2023-07-27 11:38:19,825 - rbm_models.clust_dbn — INFO — LOSS: 0.569685\n",
            "Epoch 5/15 STDEV  0.0\n",
            "100% 3861/3861 [00:52<00:00, 73.27it/s]\n",
            "2023-07-27 11:39:12,520 - rbm_models.clust_dbn — INFO — LOSS: 0.559394\n",
            "Epoch 6/15 STDEV  0.001\n",
            "100% 3861/3861 [01:13<00:00, 52.39it/s]\n",
            "2023-07-27 11:40:26,217 - rbm_models.clust_dbn — INFO — LOSS: 0.553633\n",
            "Epoch 7/15 STDEV  0.0001\n",
            "100% 3861/3861 [01:11<00:00, 54.17it/s]\n",
            "2023-07-27 11:41:37,498 - rbm_models.clust_dbn — INFO — LOSS: 0.550132\n",
            "Epoch 8/15 STDEV  1e-05\n",
            "100% 3861/3861 [01:12<00:00, 53.49it/s]\n",
            "2023-07-27 11:42:49,679 - rbm_models.clust_dbn — INFO — LOSS: 0.548528\n",
            "Epoch 9/15 STDEV  1e-06\n",
            "100% 3861/3861 [01:08<00:00, 56.01it/s]\n",
            "2023-07-27 11:43:58,615 - rbm_models.clust_dbn — INFO — LOSS: 0.546601\n",
            "Epoch 10/15 STDEV  0.0\n",
            "100% 3861/3861 [00:51<00:00, 74.82it/s]\n",
            "2023-07-27 11:44:50,221 - rbm_models.clust_dbn — INFO — LOSS: 0.544629\n",
            "Epoch 11/15 STDEV  0.001\n",
            "100% 3861/3861 [01:08<00:00, 56.59it/s]\n",
            "2023-07-27 11:45:58,445 - rbm_models.clust_dbn — INFO — LOSS: 0.543199\n",
            "Epoch 12/15 STDEV  0.0001\n",
            "100% 3861/3861 [01:10<00:00, 54.79it/s]\n",
            "2023-07-27 11:47:08,910 - rbm_models.clust_dbn — INFO — LOSS: 0.542672\n",
            "Epoch 13/15 STDEV  1e-05\n",
            "100% 3861/3861 [01:12<00:00, 53.35it/s]\n",
            "2023-07-27 11:48:21,283 - rbm_models.clust_dbn — INFO — LOSS: 0.542529\n",
            "Epoch 14/15 STDEV  1e-06\n",
            "100% 3861/3861 [01:09<00:00, 55.31it/s]\n",
            "2023-07-27 11:49:31,097 - rbm_models.clust_dbn — INFO — LOSS: 0.541075\n",
            "Epoch 15/15 STDEV  0.0\n",
            "100% 3861/3861 [00:50<00:00, 76.23it/s]\n",
            "2023-07-27 11:50:21,747 - rbm_models.clust_dbn — INFO — LOSS: 0.539623\n",
            "LABEL tensor(88) 819417\n",
            "TRAINING MODEL  14  /  150\n",
            "2023-07-27 11:50:21,748 - learnergy.core.model — DEBUG — Device: cuda.\n",
            "HERE SUBSET STATS -8.9276705 6.9164705 0.0102520175 0.7383577\n",
            "| ID | GPU | MEM |\n",
            "------------------\n",
            "|  0 |  0% | 15% |\n",
            "  0% 0/8194 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "100% 8194/8194 [00:52<00:00, 155.12it/s]\n",
            "Epoch 1/15 STDEV  0.001\n",
            "100% 8194/8194 [02:19<00:00, 58.84it/s]\n",
            "2023-07-27 11:53:34,499 - rbm_models.clust_dbn — INFO — LOSS: 1.021908\n",
            "Epoch 2/15 STDEV  0.0001\n",
            "100% 8194/8194 [02:24<00:00, 56.61it/s]\n",
            "2023-07-27 11:55:59,246 - rbm_models.clust_dbn — INFO — LOSS: 0.711891\n",
            "Epoch 3/15 STDEV  1e-05\n",
            "100% 8194/8194 [02:27<00:00, 55.65it/s]\n",
            "2023-07-27 11:58:26,495 - rbm_models.clust_dbn — INFO — LOSS: 0.630637\n",
            "Epoch 4/15 STDEV  1e-06\n",
            "100% 8194/8194 [02:27<00:00, 55.64it/s]\n",
            "2023-07-27 12:00:53,755 - rbm_models.clust_dbn — INFO — LOSS: 0.595489\n",
            "Epoch 5/15 STDEV  0.0\n",
            "100% 8194/8194 [01:54<00:00, 71.72it/s]\n",
            "2023-07-27 12:02:48,008 - rbm_models.clust_dbn — INFO — LOSS: 0.581871\n",
            "Epoch 6/15 STDEV  0.001\n",
            "100% 8194/8194 [02:33<00:00, 53.23it/s]\n",
            "2023-07-27 12:05:21,953 - rbm_models.clust_dbn — INFO — LOSS: 0.576367\n",
            "Epoch 7/15 STDEV  0.0001\n",
            "100% 8194/8194 [02:28<00:00, 55.21it/s]\n",
            "2023-07-27 12:07:50,375 - rbm_models.clust_dbn — INFO — LOSS: 0.574017\n",
            "Epoch 8/15 STDEV  1e-05\n",
            "100% 8194/8194 [02:26<00:00, 55.93it/s]\n",
            "2023-07-27 12:10:16,889 - rbm_models.clust_dbn — INFO — LOSS: 0.572479\n",
            "Epoch 9/15 STDEV  1e-06\n",
            "100% 8194/8194 [02:27<00:00, 55.49it/s]\n",
            "2023-07-27 12:12:44,562 - rbm_models.clust_dbn — INFO — LOSS: 0.571326\n",
            "Epoch 10/15 STDEV  0.0\n",
            "100% 8194/8194 [01:52<00:00, 72.62it/s]\n",
            "2023-07-27 12:14:37,401 - rbm_models.clust_dbn — INFO — LOSS: 0.570101\n",
            "Epoch 11/15 STDEV  0.001\n",
            "100% 8194/8194 [02:27<00:00, 55.64it/s]\n",
            "2023-07-27 12:17:04,661 - rbm_models.clust_dbn — INFO — LOSS: 0.569297\n",
            "Epoch 12/15 STDEV  0.0001\n",
            "100% 8194/8194 [02:29<00:00, 54.72it/s]\n",
            "2023-07-27 12:19:34,409 - rbm_models.clust_dbn — INFO — LOSS: 0.568357\n",
            "Epoch 13/15 STDEV  1e-05\n",
            "100% 8194/8194 [02:33<00:00, 53.44it/s]\n",
            "2023-07-27 12:22:07,738 - rbm_models.clust_dbn — INFO — LOSS: 0.568506\n",
            "Epoch 14/15 STDEV  1e-06\n",
            "100% 8194/8194 [02:30<00:00, 54.57it/s]\n",
            "2023-07-27 12:24:37,888 - rbm_models.clust_dbn — INFO — LOSS: 0.567459\n",
            "Epoch 15/15 STDEV  0.0\n",
            "100% 8194/8194 [01:47<00:00, 76.45it/s]\n",
            "2023-07-27 12:26:25,066 - rbm_models.clust_dbn — INFO — LOSS: 0.566520\n",
            "LABEL tensor(89) 7079307\n",
            "TRAINING MODEL  15  /  150\n",
            "2023-07-27 12:26:25,067 - learnergy.core.model — DEBUG — Device: cuda.\n",
            "HERE SUBSET STATS -8.9276705 30.682579 -0.5628477 1.4085237\n",
            "| ID | GPU | MEM |\n",
            "------------------\n",
            "|  0 |  0% | 17% |\n",
            "  0% 0/70793 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "100% 70793/70793 [07:36<00:00, 155.21it/s]\n",
            "Epoch 1/15 STDEV  0.001\n",
            "100% 70793/70793 [20:24<00:00, 57.83it/s]\n",
            "2023-07-27 12:54:29,509 - rbm_models.clust_dbn — INFO — LOSS: 0.463640\n",
            "Epoch 2/15 STDEV  0.0001\n",
            "100% 70793/70793 [20:31<00:00, 57.50it/s]\n",
            "2023-07-27 13:15:00,669 - rbm_models.clust_dbn — INFO — LOSS: 0.412478\n",
            "Epoch 3/15 STDEV  1e-05\n",
            "100% 70793/70793 [21:28<00:00, 54.93it/s]\n",
            "2023-07-27 13:36:29,465 - rbm_models.clust_dbn — INFO — LOSS: 0.404894\n",
            "Epoch 4/15 STDEV  1e-06\n",
            "100% 70793/70793 [21:56<00:00, 53.76it/s]\n",
            "2023-07-27 13:58:26,279 - rbm_models.clust_dbn — INFO — LOSS: 0.371862\n",
            "Epoch 5/15 STDEV  0.0\n",
            "100% 70793/70793 [16:59<00:00, 69.44it/s]\n",
            "2023-07-27 14:15:25,696 - rbm_models.clust_dbn — INFO — LOSS: 0.086447\n",
            "Epoch 6/15 STDEV  0.001\n",
            "100% 70793/70793 [22:11<00:00, 53.15it/s]\n",
            "2023-07-27 14:37:37,625 - rbm_models.clust_dbn — INFO — LOSS: 0.000000\n",
            "Epoch 7/15 STDEV  0.0001\n",
            "100% 70793/70793 [21:17<00:00, 55.41it/s]\n",
            "2023-07-27 14:58:55,146 - rbm_models.clust_dbn — INFO — LOSS: 0.000000\n",
            "Epoch 8/15 STDEV  1e-05\n",
            "100% 70793/70793 [21:19<00:00, 55.34it/s]\n",
            "2023-07-27 15:20:14,429 - rbm_models.clust_dbn — INFO — LOSS: 0.000000\n",
            "Epoch 9/15 STDEV  1e-06\n",
            "100% 70793/70793 [21:09<00:00, 55.74it/s]\n",
            "2023-07-27 15:41:24,417 - rbm_models.clust_dbn — INFO — LOSS: 0.000000\n",
            "Epoch 10/15 STDEV  0.0\n",
            "100% 70793/70793 [16:38<00:00, 70.93it/s]\n",
            "2023-07-27 15:58:02,442 - rbm_models.clust_dbn — INFO — LOSS: 0.000000\n",
            "Epoch 11/15 STDEV  0.001\n",
            "100% 70793/70793 [23:17<00:00, 50.67it/s]\n",
            "2023-07-27 16:21:19,515 - rbm_models.clust_dbn — INFO — LOSS: 0.000000\n",
            "Epoch 12/15 STDEV  0.0001\n",
            "100% 70793/70793 [23:38<00:00, 49.90it/s]\n",
            "2023-07-27 16:44:58,353 - rbm_models.clust_dbn — INFO — LOSS: 0.000000\n",
            "Epoch 13/15 STDEV  1e-05\n",
            "100% 70793/70793 [22:55<00:00, 51.48it/s]\n",
            "2023-07-27 17:07:53,432 - rbm_models.clust_dbn — INFO — LOSS: 0.000000\n",
            "Epoch 14/15 STDEV  1e-06\n",
            "100% 70793/70793 [22:08<00:00, 53.30it/s]\n",
            "2023-07-27 17:30:01,728 - rbm_models.clust_dbn — INFO — LOSS: 0.000000\n",
            "Epoch 15/15 STDEV  0.0\n",
            "100% 70793/70793 [15:55<00:00, 74.09it/s]\n",
            "2023-07-27 17:45:57,277 - rbm_models.clust_dbn — INFO — LOSS: 0.000000\n",
            "LABEL tensor(105) 164470\n",
            "TRAINING MODEL  16  /  150\n",
            "2023-07-27 17:45:57,278 - learnergy.core.model — DEBUG — Device: cuda.\n",
            "HERE SUBSET STATS -5.956113 9.183313 0.49251658 0.536787\n",
            "| ID | GPU | MEM |\n",
            "------------------\n",
            "|  0 |  0% | 11% |\n",
            "  0% 0/1644 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "100% 1644/1644 [00:11<00:00, 137.02it/s]\n",
            "Epoch 1/15 STDEV  0.001\n",
            "100% 1644/1644 [00:32<00:00, 50.79it/s]\n",
            "2023-07-27 17:46:41,810 - rbm_models.clust_dbn — INFO — LOSS: 1.518472\n",
            "Epoch 2/15 STDEV  0.0001\n",
            "100% 1644/1644 [00:30<00:00, 53.54it/s]\n",
            "2023-07-27 17:47:12,520 - rbm_models.clust_dbn — INFO — LOSS: 1.060075\n",
            "Epoch 3/15 STDEV  1e-05\n",
            "100% 1644/1644 [00:30<00:00, 53.06it/s]\n",
            "2023-07-27 17:47:43,507 - rbm_models.clust_dbn — INFO — LOSS: 1.011357\n",
            "Epoch 4/15 STDEV  1e-06\n",
            "100% 1644/1644 [00:30<00:00, 53.82it/s]\n",
            "2023-07-27 17:48:14,053 - rbm_models.clust_dbn — INFO — LOSS: 0.986457\n",
            "Epoch 5/15 STDEV  0.0\n",
            "100% 1644/1644 [00:22<00:00, 72.90it/s]\n",
            "2023-07-27 17:48:36,607 - rbm_models.clust_dbn — INFO — LOSS: 0.971577\n",
            "Epoch 6/15 STDEV  0.001\n",
            "100% 1644/1644 [00:30<00:00, 53.22it/s]\n",
            "2023-07-27 17:49:07,501 - rbm_models.clust_dbn — INFO — LOSS: 0.959758\n",
            "Epoch 7/15 STDEV  0.0001\n",
            "100% 1644/1644 [00:30<00:00, 53.97it/s]\n",
            "2023-07-27 17:49:37,964 - rbm_models.clust_dbn — INFO — LOSS: 0.953034\n",
            "Epoch 8/15 STDEV  1e-05\n",
            "100% 1644/1644 [00:30<00:00, 53.36it/s]\n",
            "2023-07-27 17:50:08,778 - rbm_models.clust_dbn — INFO — LOSS: 0.947471\n",
            "Epoch 9/15 STDEV  1e-06\n",
            "100% 1644/1644 [00:30<00:00, 53.75it/s]\n",
            "2023-07-27 17:50:39,366 - rbm_models.clust_dbn — INFO — LOSS: 0.942601\n",
            "Epoch 10/15 STDEV  0.0\n",
            "100% 1644/1644 [00:22<00:00, 73.60it/s]\n",
            "2023-07-27 17:51:01,705 - rbm_models.clust_dbn — INFO — LOSS: 0.938386\n",
            "Epoch 11/15 STDEV  0.001\n",
            "100% 1644/1644 [00:33<00:00, 49.12it/s]\n",
            "2023-07-27 17:51:35,177 - rbm_models.clust_dbn — INFO — LOSS: 0.935826\n",
            "Epoch 12/15 STDEV  0.0001\n",
            "100% 1644/1644 [00:30<00:00, 53.45it/s]\n",
            "2023-07-27 17:52:05,936 - rbm_models.clust_dbn — INFO — LOSS: 0.933449\n",
            "Epoch 13/15 STDEV  1e-05\n",
            "100% 1644/1644 [00:30<00:00, 53.36it/s]\n",
            "2023-07-27 17:52:36,748 - rbm_models.clust_dbn — INFO — LOSS: 0.930886\n",
            "Epoch 14/15 STDEV  1e-06\n",
            "100% 1644/1644 [00:31<00:00, 52.19it/s]\n",
            "2023-07-27 17:53:08,250 - rbm_models.clust_dbn — INFO — LOSS: 0.928449\n",
            "Epoch 15/15 STDEV  0.0\n",
            "100% 1644/1644 [00:23<00:00, 70.29it/s]\n",
            "2023-07-27 17:53:31,640 - rbm_models.clust_dbn — INFO — LOSS: 0.926602\n",
            "LABEL tensor(112) 1851729\n",
            "TRAINING MODEL  17  /  150\n",
            "2023-07-27 17:53:31,641 - learnergy.core.model — DEBUG — Device: cuda.\n",
            "HERE SUBSET STATS -4.9244637 9.183313 0.5044472 0.55612636\n",
            "| ID | GPU | MEM |\n",
            "------------------\n",
            "|  0 |  0% | 10% |\n",
            "  0% 0/18517 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "100% 18517/18517 [02:02<00:00, 150.96it/s]\n",
            "Epoch 1/15 STDEV  0.001\n",
            " 36% 6736/18517 [02:02<03:32, 55.35it/s]"
          ]
        }
      ],
      "source": [
        "%env PYTHONPATH=$PYTHONPATH:/content/learnergy/:/content/SIT_FUSE/\n",
        "!cd SIT_FUSE; torchrun --nnodes=1 --nproc_per_node=1 dbn_learnergy_heirarchical.py --yaml /content/SIT_FUSE/config/dbn/palm_oil_dbn_colab.yaml"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **GeoTiff/Intermediate Product Generation**"
      ],
      "metadata": {
        "id": "u9nLMgxi_WQH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ih2yBvlBjqDI",
        "outputId": "e06219f7-79ed-4c8c-e7eb-86848ea2fca4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "env: PYTHONPATH=$PYTHONPATH:/content/learnergy/:/content/SIT_FUSE/\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/SIT_FUSE/postprocessing/generate_cluster_geotiffs.py\", line 484, in <module>\n",
            "    main(args.yaml)\n",
            "  File \"/content/SIT_FUSE/postprocessing/generate_cluster_geotiffs.py\", line 470, in main\n",
            "    generate_cluster_gtiffs(data_reader = reader, data_reader_kwargs = data_reader_kwargs, subset_inds = subset_inds,\n",
            "  File \"/content/SIT_FUSE/postprocessing/generate_cluster_geotiffs.py\", line 136, in generate_cluster_gtiffs\n",
            "    dbnDat1 = read_func(cluster_data[p], **data_reader_kwargs).astype(np.int32)\n",
            "  File \"/content/SIT_FUSE/utils.py\", line 66, in numpy_from_zarr\n",
            "    return np.array(zarr_load(filename).compute())\n",
            "  File \"/content/SIT_FUSE/utils.py\", line 63, in zarr_load\n",
            "    return da.from_zarr(filename)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/dask/array/core.py\", line 3593, in from_zarr\n",
            "    z = zarr.Array(store, read_only=True, path=component, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/zarr/core.py\", line 224, in __init__\n",
            "    self._load_metadata()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/zarr/core.py\", line 243, in _load_metadata\n",
            "    self._load_metadata_nosync()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/zarr/core.py\", line 252, in _load_metadata_nosync\n",
            "    meta_bytes = self._store[mkey]\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/zarr/storage.py\", line 1111, in __getitem__\n",
            "    return self._fromfile(filepath)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/zarr/storage.py\", line 1086, in _fromfile\n",
            "    return f.read()\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "%env PYTHONPATH=$PYTHONPATH:/content/learnergy/:/content/SIT_FUSE/\n",
        "!cd SIT_FUSE/postprocessing/; python3 generate_cluster_geotiffs.py --yaml ../config/postprocess/palm_oil_geotiff_gen_colab.yaml"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_fx82tI10vOO"
      },
      "source": [
        "## **Generate Final Product**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%env PYTHONPATH=$PYTHONPATH:/content/learnergy/:/content/SIT_FUSE/\n",
        "!cd SIT_FUSE/postprocessing/; python3 contour_and_fill.py --yaml ../config/postprocess/palm_oil_contour_colab.yaml"
      ],
      "metadata": {
        "id": "fjdgQK6iBQF7"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuClass": "premium",
      "collapsed_sections": [
        "y22xv4q_9gqW",
        "1efsJNFl9nCa",
        "8byhqFwC99Aw",
        "6m84awvJ-EZK",
        "eoueQC9u-kjv",
        "ro15XP8b-t8Z"
      ]
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}