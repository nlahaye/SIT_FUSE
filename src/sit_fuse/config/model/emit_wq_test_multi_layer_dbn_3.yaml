
data:
 tile: False
 num_loader_workers: 10
 val_percent: 0.1
 scale_data: True
 pixel_padding: 0
 number_channels: 244
 fill_value: -9999.0
 valid_min:  -9000.0
 valid_max: 100000000
 subset_count: 1
 output_subset_count: 10
 reader_type: "emit_l2"
 reader_kwargs:
  mask_shp: "/data/nlahaye/remoteSensing/Lakes/glwd_1.shp"
 chan_dim: 0
 delete_chans: [84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284] 
 transform_default:
  chans: []
  transform: []


 files_train: [
["/data/nlahaye/remoteSensing/EMIT_WQ/EMIT_L2A_RFL_001_20240626T152155_2417810_031.nc", "/data/nlahaye/remoteSensing/EMIT_WQ/EMIT_L2A_RFL_001_20240626T152155_2417810_031.tif", "/data/nlahaye/remoteSensing/EMIT_WQ/EMIT_L2A_RFL_001_20240626T152155_2417810_031.tif.lonlat.zarr"],
["/data/nlahaye/remoteSensing/EMIT_WQ/EMIT_L2A_RFL_001_20240621T160541_2417311_026.nc", "/data/nlahaye/remoteSensing/EMIT_WQ/EMIT_L2A_RFL_001_20240621T160541_2417311_026.tif", "/data/nlahaye/remoteSensing/EMIT_WQ/EMIT_L2A_RFL_001_20240621T160541_2417311_026.tif.lonlat.zarr"],
["/data/nlahaye/remoteSensing/EMIT_WQ/EMIT_L2A_RFL_001_20230729T223029_2321015_001.nc", "/data/nlahaye/remoteSensing/EMIT_WQ/EMIT_L2A_RFL_001_20230729T223029_2321015_001.tif", "/data/nlahaye/remoteSensing/EMIT_WQ/EMIT_L2A_RFL_001_20230729T223029_2321015_001.tif.lonlat.zarr"]
]

 files_test: [
["/data/nlahaye/remoteSensing/EMIT_WQ/EMIT_L2A_RFL_001_20240626T152144_2417810_030.nc", "/data/nlahaye/remoteSensing/EMIT_WQ/EMIT_L2A_RFL_001_20240626T152144_2417810_030.tif", "/data/nlahaye/remoteSensing/EMIT_WQ/EMIT_L2A_RFL_001_20240626T152144_2417810_030.tif.lonlat.zarr"],
["/data/nlahaye/remoteSensing/EMIT_WQ/EMIT_L2A_RFL_001_20230419T173941_2310912_005.nc", "/data/nlahaye/remoteSensing/EMIT_WQ/EMIT_L2A_RFL_001_20230419T173941_2310912_005.tif", "/data/nlahaye/remoteSensing/EMIT_WQ/EMIT_L2A_RFL_001_20230419T173941_2310912_005.tif.lonlat.zarr"],
["/data/nlahaye/remoteSensing/EMIT_WQ/EMIT_L2A_RFL_001_20240621T160553_2417311_027.nc", "/data/nlahaye/remoteSensing/EMIT_WQ/EMIT_L2A_RFL_001_20240621T160553_2417311_027.tif", "/data/nlahaye/remoteSensing/EMIT_WQ/EMIT_L2A_RFL_001_20240621T160553_2417311_027.tif.lonlat.zarr"]
]




scaler:
 name: "standard" 

output:
 out_dir: "/data/nlahaye/output/Learnergy/EMIT_WQ_REDUCED/"
 generate_intermediate_output: True


dbn:
 model_type: ["gaussian_selu", "gaussian_selu"]
 dbn_arch: [2000, 1000] #[250, 500, 2000] #, 2000]
 gibbs_steps: [1,1] #, 7, 7] #, 10] #, 25]
 temp: [1.0, 1.0] #, 1.0, 1.0] ##[0.9, 0.75, 0.5] #, 1.0] #, 0.5] #, 0.5] 
 normalize_learnergy: [False, True]
 batch_normalize: [False, False]

encoder_type: "dbn"
encoder:
 tiled: False
 tune_scaler: False
 subset_training: 2500000
 overwrite_model: False
 training:
  learning_rate: [0.00001, 0.00001]
  momentum: [0.95,0.95]
  weight_decay: [0.0001, 0.0001]
  nesterov_accel: [True, True]
  batch_size: 128
  epochs: 30
  accelerator: "gpu"
  devices: 1
  gradient_clip_val: 0.1
  precision: "16-mixed"
  save_dir: "wandb_encoder"
  stratify_data:
   kmeans: True


logger:
 use_wandb: True
 log_model: True
 log_out_dir: "wandb_dbn"
 project: "SIT-FUSE"

cluster:
 gauss_noise_stdev:  [0.01]
 lambda: 1.0
 num_classes: 800
 training:
  learning_rate: 0.0001
  batch_size: 1000
  epochs: 30
  accelerator: "gpu"
  devices: 1
  gradient_clip_val: 0.1
  precision: "16-mixed"
  save_dir: "wandb_full_model"

 heir:
  tiers: 1
  gauss_noise_stdev:  [0.01]
  lambda: 1.0
  num_classes: 100
  training:
   accelerator: "gpu"
   devices: 1
   gradient_clip_val: 0.1
   precision: "16-mixed"
   save_dir: "wandb_dbn_full_model_heir"
   batch_size: 100
   min_samples: 1000
   learning_rate: 0.0001
   batch_size: 1000
   epochs: 30



