
data:
 data:
 tile: True
 val_percent: 0.1
 tile_size: [16,16,8]
 tile_step: [16,16,8]
 val_percent: 0.1
 num_loader_workers: 10
 scale_data: True
 pixel_padding: 1
 number_channels: 8
 fill_value: -99999.0
 valid_min: -900.0
 valid_max: 100000000
 reader_type: "gtiff"
 reader_kwargs:
  no_arg: ''
 chan_dim: 0
 delete_chans: []
 transform_default:
  chans: []
  transform: []

 files_train: [
"/data/nlahaye/remoteSensing/Palm_Oil/ucayali_stacks_2020_h1v1.tif",
"/data/nlahaye/remoteSensing/Palm_Oil/ucayali_stacks_2020_h0v2.tif",
"/data/nlahaye/remoteSensing/Palm_Oil/ucayali_stacks_2020_h1v3.tif"]


 files_test: [
"/data/nlahaye/remoteSensing/Palm_Oil/ucayali_stacks_2020_h1v1.tif",
"/data/nlahaye/remoteSensing/Palm_Oil/ucayali_stacks_2020_h0v1.tif",
"/data/nlahaye/remoteSensing/Palm_Oil/ucayali_stacks_2020_h0v2.tif",
"/data/nlahaye/remoteSensing/Palm_Oil/ucayali_stacks_2020_h1v0.tif",
"/data/nlahaye/remoteSensing/Palm_Oil/ucayali_stacks_2020_h1v1.tif",
"/data/nlahaye/remoteSensing/Palm_Oil/ucayali_stacks_2020_h1v2.tif",
"/data/nlahaye/remoteSensing/Palm_Oil/ucayali_stacks_2020_h1v3.tif",
"/data/nlahaye/remoteSensing/Palm_Oil/ucayali_stacks_2020_h2v0.tif",
"/data/nlahaye/remoteSensing/Palm_Oil/ucayali_stacks_2020_h2v1.tif",
"/data/nlahaye/remoteSensing/Palm_Oil/ucayali_stacks_2020_h2v2.tif",
"/data/nlahaye/remoteSensing/Palm_Oil/ucayali_stacks_2020_h2v3.tif",
"/data/nlahaye/remoteSensing/Palm_Oil/ucayali_stacks_2020_h4v2.tif",
"/data/nlahaye/remoteSensing/Palm_Oil/ucayali_stacks_2020_h4v3.tif"]



output:
 out_dir: "/data/nlahaye/output/Learnergy/JEPA_OIL_PALM/"
 generate_intermediate_output: True
 generate_train_output: True

scaler:
 name: "standard" 


logger:
 use_wandb: True
 log_model: True
 log_out_dir: "wandb_full"
 project: "SIT-FUSE"


ijepa:
 patch_size: 1
 embed_dim: 1024 
 encoder_heads: 3
 encoder_depth: 6
 decoder_depth: 5
 target_aspect_ratio: [0.75,1.5] #1,1
 target_scale: [0.15, .2] #1,1
 context_aspect_ratio: 1
 context_scale: [0.85,1.0]
 number_target_blocks: 6

encoder_type: "ijepa"
encoder:
 subset_training: 10000 #2300000
 overwrite_model: False
 tune_scaler: False
 training:
  weight_decay: 0.05
  momentum: 0.996
  momentum_start_end: [0.996, 1.0] 
  learning_rate: 0.0001
  batch_size: 100
  epochs: 5
  accelerator: "gpu"
  devices: 1
  gradient_clip_val: 0.1
  precision: "16-mixed"
  save_dir: "wandb_ijepa_full"
  stratify_data:
   kmeans: True

cluster:
 gauss_noise_stdev:  [0.01]
 lambda: 1.0
 num_classes: 800
 training:
  finetune_encoder: False
  learning_rate: 0.00001
  batch_size: 10
  epochs: 5
  accelerator: "gpu"
  devices: 1
  gradient_clip_val: 0.1
  precision: "16-mixed"
  save_dir: "wandb_ijepa_full"

 heir:
  tiers: 1
  gauss_noise_stdev:  [0.01]
  lambda: 1.0
  num_classes: 100
  training:
   accelerator: "gpu"
   devices: 1
   gradient_clip_val: 0.1
   precision: "32"
   save_dir: "wandb_ijepa_full"
   batch_size: 10
   min_samples: 1000
   epochs: 10
   lambda: 1.0
 
